Mark:               I can interpret it any way I want.
                    Hey, Dan.

Dan:                Sorry. So, that didn't clear anything up. Sorry about that. I needed to cycle. I had resources getting contested and fun stuff like that.
                    All right. So, since I haven't had time to bug folks, did everyone already sign up for Scribe? No. So, if I could get a couple scribes, we're going to kick off our use case exploration again, and we have a special guest today, Dr Roy has joined us. Arnab Roy here to continue some of the discussion that Mark shared with us, and soon as we get two scribes a-scribing, we can get started.

Mark:               I can be one of them. It's Mark. 

Dan:                Great, thank you, Mark.
                    Okay, I need one more. Anyone else want to join Mark in CaptureNotes today?
                    All right. Well, in the sake of time, I'm going to put my name down and join Mark, and that'll allow us to get started. All right. So, before we dive into the use case with Dr Roy, I'd like to give the opportunity to have check-ins from any of the SIGs and working groups. Anything in SIG [inaudible 00:03:07] or the policy working group that anyone has to share?
                    Okay. Still, Mark, maybe you could introduce Dr Roy, and connect the dots from the discussion that you shared with us, and what we have today?

Mark:               Sure, if you'd like to do that.

Dan:                Awesome. Thank you.

Mark:               And this Big Data Working Group has been cranking along since the summer of 2013. This is not a standards body per se; the output is three technical reports, of which we've produced one. Another one is review at NIST; it'll probably come out in the next five or six weeks, maybe before that. We haven't got around to publishing our papers, but we're working on that, aren't we? 
                    Arnab and I co-chaired the Security and Privacy sub-group of that Big Data Working Group. And in that role, Arnab is the primary guy that covers all the crypto aspects of that. So while we worked on the models together, and basically hammered out the drafts together, and helped adjudicate the content we got from other third parties, he's really the primary contributor to our backgrounding on blockchain, crypto aspects of data at rest, and what the role of some of those things might be, and some of the emerging big data technologies. So he's really the better of the two of us to present those aspects of it.
                    He also had some experience previously in the cloud security group. Maybe you'll want to mention that, Arnab, when you kick that off. Over to you, buddy.

Arnab Roy:          Thanks, Mark. Can you hear me?

Mark:               Yeah. Thank you.

Arnab Roy:          Okay. So, I really got scared when you said the use cases, because what I'm going to talk about is not as much a use case, but an overview of the document that we are going to talk about. Is that okay?

Dan:                That's great. You know, for us, considering the [inaudible 00:05:25] that we're doing, and gaining an understanding of what's going on in the ecosystems broadly characterizes use cases. But yeah, that's fine.

Arnab Roy:          Right. But before I dive in, this is my first time to this meeting, and thanks for inviting me, by the way. But can you give me a very short overview of what this working group does, so that maybe I can tailor my presentation better?

Dan:                You bet. I'll give you our elevator pitch. So, the Safe Working Group exists in the cloud native space. We are a proposed working group for the CNCF. There are very few of those. There's Infrastructure in CI and a couple of others, Serverless. In the actual CNCF and cloud native overarching ecosystem, there are very few of these working group. If you go down into Kubernetes, there is an extensive ecosystem of SIGs, special interest groups, and working groups that are operating there.
                    And what we're focused on in the Safe Working Group is safety in this cloud ecosystem where you have the operator, the administrator, the developer, the end user, and we're trying to build understanding and shared vocabulary around how we make sure that there's secure access and operational safety in place, that all of those parties in this new cloud ecosystem ... That everyone has a clear sense of what's going on there.

Arnab Roy:          I see. Thanks, Dan, for that overview, and it seems like I'll be preaching to the choir, so [inaudible 00:07:35] for that. 
                    What I would say might seem juvenile to you. And, you know, as you talked about your role, it seems like many of the metaphors that we use in the Big Data Working Group might just carry over to your group, and we would like to hear, maybe now, maybe later, how these things that we talk about in our documents are relevant to you guys.
                    So, I would like to share a presentation on the screen. Let me try to see if I can do that.

Dan:                There's a big green button that says Share Screen at the bottom.

Arnab Roy:          Share Screen? Okay. 
                    Okay? Can you see this?

Dan:                Looks good.

Arnab Roy:          Okay. So, what I'm going to talk about is the security and privacy of big data. It's a NIST perspective, that is the perspective of the document that we produced in our working group. And Mark has contributed a lot to this document.
                    So, we started off this working group with a lot of discussion on: what is big data? So, this was back in 2013, and there were very diverse opinions on what constitutes big data. I'm sure the answer is not canonized, even now. But this is the definition we came up with in our document. It may not be perfect, but it was the consensus.
                    So, it goes like: big data consists of extensive data sets in the characteristics of volume, variety, velocity, and/or variability, that require a scalable architecture for efficient storage, manipulation, and analysis. And this definition is there in part one of our document.
                    So, of course security and privacy are important for big data, you all know that, so I don't have to go through this slide. Essentially, it says that it's very important, because it causes damage to companies' reputation when data breaches occur. And that can be evaluated in dollars.
                    So, the Big Data Working Group started out with five sub groups: Definitions and Taxonomies; Use Cases and Requirements; Security and Privacy; Reference Architecture; Standards Roadmap. The sub groups have kind of spread out from 2013 to now, so we may have more deliverables than sub groups at this point. At this point, the definitions are a bit nebulous. But the deliverables are what you see on the right, one through seven. And number four is the Big Data, Security, and Privacy document, which I'm going to talk about.
                    So, we released our Version One two years ago. And the NIST SP1500-4 is our document. And it's available on the site that I gave a link to in the slide. Version Two draft, as Mark said, it's in NIST review phase. Public comments are received on September 21st. And the public comments version is also available on the web.
                    So, given that background, I'll go into some of the characteristics that we identify in the document that are seemingly different for big data compared to what was before. So, we spent a lot of time understanding what is emergent about the security and privacy of big data, given its principal characteristics. So it seemed that there were two aspects. One is due to scaling, and this you can attribute to the volume and velocity characteristics of big data. And it has to do with many things; I'll cover those in the next slide.
                    The other more foundational aspect is mixing. And this is the notion that a very important characteristic of big data is that you get data from diverse endpoints, and a huge amount of data. And some of that data may not be completely accurate as well. So you get this mixing characteristic, which can be attributed loosely to the variety and veracity characteristics of big data. And that causes emergent problems for security and privacy.
                    So, to go into some amount of detail, so on the left is what are different are due to scaling; on the right, what are different due to mixing. So, the scaling problem can be summarized as: how do you re-target your existing systems due to the infrastructural shift because of big data? So, the infrastructural shift is due to various things, like distributed computing platforms lik Hadoop, non-relational data stores, et cetera. So paradigm shifts in infrastructural thinking has required, is still requiring, new solutions in security and privacy.
                    The other is a more foundational aspect, the mixing aspect. And here, the problem is to control the visibility of data while enabling utility. So, what is this about? Here, the principal questions are: how do you balance privacy and utility? You get a lot of data, and to be useful, all that data needs to be used, but then you also run into these privacy aspects, where you can mine different sorts of data about different individuals, and you get a bigger picture that cannot be quite apparent from individual data sets alone.
                    How do you enable analytics and governance on encrypted data? And then, finally, how do you reconcile authentication and anonymity, which, on the face of it, seem to be at conflict? So, these aspects are all described in Section Two of our doc.
                    We then go into some amount of depth regarding: how do you characterize different security and privacy aspects that arise due to these principal aspects of big data? So, there are five V-words that were identified: volume, velocity, variety, veracity, volatility. And what I give in this slide and the next one are examples of security and privacy concerns that arise especially due to each of these characteristics.
                    So, for example, the variety characteristic of big data is apparent where traditional encryption schemes which render data into a random collection of bits, that hinders organization of data based on semantics. Then, volume of big data requires that you store them in multi-tiered data storages. So that is a lot of back and forth of data between different storages, and all of this communication requires threat models to identify: is the communication secure or not? Is the data being handled properly or not? But these are complex and evolving issues. And then the velocity aspect is the re-targeting that I talked about. So, data is coming at a very fast pace; how do you re-target traditional security mechanisms to support this? 
                    So, veracity has to do with provenance, as Mark talked about last time. So, this is keeping track and ensuring integrity of the ownership, source, and other metadata of individual data, and how do you take care of that, given the complex movement of data between nodes, entities, and geographical boundaries. Volatility of data is another big aspect. So, indefinitely persistent data requires involving S&P considerations, because the ownership may change in mergers and acquisitions and so on. Who takes ownership and responsibility of keeping the data safe?
                    So, these are characteristics of big data, enforcing new requirements in security and privacy. We then, in Section Four, try to classify security and privacy topics. We have two kinds of classification. One is cross-domain and cross-infrastructure, and trying to look at the type of property that each S&P requirement is. So some properties are privacy properties: you want to keep data secret or safe, confidential. Provenance properties: you want to keep the data accurate, you want to identify who owns the data, and so on. System health has to do with: are there security vulnerabilities and things? [inaudible 00:18:33] can somebody exploit that, how do you keep the health of the system safe? And then some of these have to do with public policy aspects, so these are things like what is right and wrong to do with data, from a policy point of view.
                    And then there are operational classifications of S&P topics. So, this has to do with the particular infrastructure that we have in place today. So, there are devices, there are identities, and you have to manage access to them. You have to govern the use and access of data. You have to manage infrastructure, and also you have to risk analyze and account for each of these aspects.
                    Are there any questions so far? Sorry, I just went on.

Dan:                No. This is really good.

Arnab Roy:          Thanks, Dan.
                    Okay. So, we covered how the characteristics of big data define new emergent S&P considerations, and we classified S&P concerns for different types of systems. A centerpiece of our working group is a reference architecture. And that becomes especially important for security and privacy. The reason is security and privacy does not compose. What do I mean? So, let's say we have two systems, System A and System B, and we have completely analyzed them. We have seen what the endpoints of System A are and what the endpoints of System B are. They have data inflows and out flows. We have complete accountability for each of them, and let's say we have guaranteed that they satisfy some security requirements. 
                    But when we put System A and System B together, then suddenly it may turn out that security properties are no longer satisfied. And that's because there may be APIs in System B which leak data from System A. So, together, they may have unknown data flow patterns that were not analyzed when they were in isolation. So combined systems can have unexpected data flows. They can destructively interfere. The point of this is, it's very important to think of S&P from an architectural standpoint. Think of the system as a whole rather than modular in parts. It's also important to look at each module individually, but then, when combining, we have to ensure additional properties.
                    So, there is a need for architectural thinking, and that's where it becomes important that we're able to [inaudible 00:21:53] big data reference architecture. So, Mark might have already talked about this, but this is also described in one of the documents in our working group, I think number six. And it conceptualizes big data systems as these boxes. We have data providers and data consumers. There is an application provider which sits in the middle of that, and it provides different connection and access capabilities. The framework provider is the underlying infrastructure, which gives processing and platforms and infrastructures. And there's a system architecture at the top, which is orchestrating all this movement.
                    And you can see that there is a security and privacy fabric all around this system. So, what is that meant to signify? It signifies that this fabric is all around the system, and you cannot think of it in isolation. So we have to think of security and privacy at each of the interfaces between the boxes, as well as internally to the boxes.
                    So, that's what we, at least preliminarily, did, in the Version One of our document, and in Section Five of the document, you can find some of the security aspects that we talked about. For example, in the interface between data provider and application provider, you have to do endpoint input validation. On the event, going from big data application provider to data consumer, there's sometimes privacy preserving data analytics and dissemmination. In the framework provider, you have need for key management, securing data storage and transaction logs, and so on.
                    And in Section Three of our document, we also talked about a bunch of use cases-

Dan:                Dr Roy, I have a question on the architecture, before you move onto the next section.

Arnab Roy:          Yeah, sure.

Dan:                So, it's a bit of a meta question; my apologies. So, when you were saying reference architecture, did you, the group there, go and actually build this out, or just laid out some of the architectural definition of what a typical system looks like?

Arnab Roy:          A combination of both. So, this was a lot of discussions, actually. It consumed a year and a half, I would say. So, we started with a lot of existing architectures. There was an architecture from IBM; there was an architecture from other places. We actually have a document in our working group that goes through each of these proprietary or public architectures. And then the group sifted through those architectures, saw what were the principal characteristics that we were looking for, and this is the architecture that evolved out of all of the discussions. So it took a lot of time to evolve.

Dan:                Right.

Arnab Roy:          Yeah. It had been evolving even until last year. So I don't think we have changed it in the last year, but that's the amount of evolution that it went through.

Dan:                Got it. And so what did you end up doing in terms of the technical [inaudible 00:25:40] of this? What kind of-

Arnab Roy:          Sorry, I did not get your question, sorry.

Dan:                So, the code component, what purpose does that end up serving for your group?

Arnab Roy:          The reference architecture itself? So, we try to describe everything with respect to the reference architecture. Even in the security and privacy document. So we try to identify how each of our concepts, each of our classifications, each of the technologies that we identify, how do they fit into the reference architecture? So that's why it constitutes a linkage piece, an arbitration point, which defines how we go through the document.

Dan:                Great. The reason why I'm asking is, this is an area where we kind of backed away from going down this path, just because taking and coalescing all those things across the cloud ecosystem seemed daunting and possibly impractical. So, I mean, good context that yeah, it does take an incredible amount of time to go and capture and distill that down.

Arnab Roy:          Yeah, I understand your point. So, Cloud Security Alliance had this huge reference architecture, with 300 boxes, right? But we opted for ... Well, one of the reasons is big data systems are so diverse. It's not as homogenous an entity as a cloud. So when we describe big data systems, big data systems are everywhere. You have healthcare, you have fundamental physics, you have aviation, you have transportation. You have so many use cases. And each of those use cases can identify at least something that may not fit readily into this architecture. But it is actually one of the reasons why our reference architecture is so succinct, instead of going into 300 little pieces of details.

Dan:                Right. Right. Makes sense.

Arnab Roy:          Because it has to homogenize an inherently inhomogeneous connection of use cases.

Dan:                Right. Great. Thank you for sharing.

Arnab Roy:          Sure. 
                    Okay. So, we collected all these use cases. Many of these are actually from Mark, and he might have talked about some of these. But overall, there were five big [inaudible 00:28:44: retail and marketing; healthcare; cyber security; government; and industrial big data. 
                    So, with that, I would like to dive into some of the cryptographic aspects that we talked about in our document. So, these are emerging cryptographic technologies, and the recommendation from this document is to be aware of these technologies and to be aware of risk-benefit analysis of choosing some of these technologies over others. So, this table is divided into various facets. So, I talk about specific cryptographic technologies on the left. These are emergent. Some of these are in limited deployment, but most of it is in research stage. And all of these technologies provide different kinds of features while affording visibility to controlled entities.
                    So, what do I mean by that? The first example is: how do you outsource computation securely? So, an example is, suppose you want to send all your sensitive data through the cloud: photos, medical records, and so on. You can send everything encrypted, but the cloud can't help you much after that. So you can't find out, for example, how much you spent on movies last month, if everything you sent to the cloud was encrypted. So, fully homomorphic encryption is a cryptotechnology which enables you to do just that. So, you encrypt your data, and then the cloud can do analogous computation, called homomorphic computation, which is a transformation of the actual computation. And then the amazing thing about this is that it only operates on ciphertexts. It never has to decrypt the data. So all processed ciphertexts are random sequence of bits to the cloud. And then the cloud can send you your processed encrypted data, and only you can decrypt it. So this is great, because the user can decrypt the process data, and there's an end-to-end security. So you get to pick your key, and so on.
                    We can also control visibility, who we give access to, based on encryption technology. So this is traditionally done by role-based active control or some other types of active control by systems, like operating systems and virtual machines. So, these usually restrict access to data, but the data is still in plain text. So, in particular, if you hack the system, you get access to the data. And when you want to send the data in transit, then the security is kind of ad-hoc, depends on system to system.
                    So now, the question we ask is: can we encrypt it in such a way that we do not have to go through all this? So decryption is only possible by entities allowed by the policy. So this is technologically enforced rather than system enforced. Well, of course, you can hack keys, but this is a much smaller attack surface. So, a key can be a few kilobytes, and you can have a very special protective mechanism to protect small keys rather than gigabytes of data. And then encrypted data can be moved around as well as kept at rest. The handling is uniform.
                    So, many of you might already know examples of this. The starting point is public key encryption. So, how public key encryption works is that there is a certificate authority; it finds certificates of public key, and then you can show ... Let's say Alice and Bob are trying to communicate, then Bob can show his signed certificate of public key, then Alice can use that public key to encrypt data, and only Bob can decrypt it. So this is just a plain public encryption.
                    Going one level higher, there's something called identity-based encryption. So here, the idea is that there is no signed certificate of public key. You can just use identity of some person, and there is just one master public key, and you just use that master public key and the identity of the person you want to encrypt to, and that's all you need to encrypt your data. Any other person, even using the same master public key, cannot decrypt your data. So, in this scenario, Alice can use the master public key and just the identity, like maybe email address, of Bob or George to encrypt the data. And only Bob or George and decrypt their respective ciphertexts.
                    So, taking this to the extreme, we have policy-based encryption. So, here, the policy can be a complex predicate, which is indicated as phi here. So, this is one simple scenario where there is a hospital, and let's say somebody can see a patient's data only if he or she is a doctor or a nurse who also works in ICU. So, this is a more complex policy predicate than just identification. So, what policy-based encryption does is enables an encrypter to encrypt to a policy rather than some [inaudible 00:35:35] entity. So you can encrypt to a policy of your choice, which can be complex, and then only people who satisfy that policy will be able to decrypt. And nobody else.
                    Finally, we also talked about blockchain. So, we avoid the financial aspect of blockchain in this document. We don't know how important that is. But there are many technological aspects of blockchain which can be really useful in the security and privacy space, especially things like asset and ownership management, transaction logging for audit and transparency, bidding for options and contract management, and so on.
                    So, the high-level recommendations are as follows. So, which technology to use among all these cryptographic technologies, it involves a lot of risk-benefit analysis. We have to consider sensitivity of the data, cost of breach, and cost of securing systems when doing this analysis. So, I gave an example where there are three different cost-benefit analysis. So, let's say we want to run the task of running software on an encrypted data address. There are three possibilities. 
                    So let's say we just do what is traditionally done, which is decrypt the data in the cloud and run software. So, your data is encrypted first, but you can decrypt it and then just run plain software on it. So, what are the pros of that? Very, very fast execution. The problem is that the server is hacked, decryption easily, all your data is exposed. 
                    The second, better option is: run the software on the decrypted data inside an hardware security modules. But the are are many hardware security modules in the market today; prominent ones are [inaudible 00:37:54] or just Amazon. So this is a little less fast than just doing computation on plain data, but it's still practical. But there are some problems which have not been solved satisfactorily yet, and these are to do with side channel attacks. And these attacks are, you can see the patterns of memory, addresses, and so on, and can infer something about something secret.
                    The final, completely secure solution is you just use fully homomorphic encryption. The pros there is it's cryptographically secure, there are no side channel attacks, it's secure against all the vulnerabilities of the last solution. It works even if you completely breach the server. But the disadvantage is that it's very slow at this point, except for limited operations.
                    So, just to conclude, there are four things that I want to take you away. Think of security and privacy at the time of architecting the overall system, not as an afterthought, which is the way many systems are designed today, unfortunately. In security and privacy, systems do not compose. So you have to re-analyze security and privacy when you add new features or join new systems. There's a lot of cryptography that is emergent; you just have to stay tuned and patient at this point. But it'll enable many remarkable operations in the future. And finally, it's very important to read the document, and we hope that you have feedback for us that is useful. We should be able to document that. Thank you.

Dan:                Great. Thank you, Dr Roy. So, I'd like to open the floor to questions or requests, either to yourself, Dr Roy, or Mark. It'd be fantastic if, in the meeting notes, we could link to not only Dr Roy's presentation, but if we could provide links to the documents. I believe, Mark, you touched on some of these in the issues, in our getup [inaudible 00:40:53]. But for those that are following along, if we can point them to a way to go deeper in this, that'd be fantastic.

Speaker 4:          Yeah, I have a question about combination of data and the way that changes ... Access control, right? We see both that, by combination, you can de-anonymize data, so data that was previously anonymized and that maybe doesn't need strong access control, suddenly by combining that, you have the need for stronger access control, and also the reverse, where you have data that gets aggregated, so the access control doesn't have to be as secure, right? Was there any thought on that in your study?

Arnab Roy:          Right, so we test on this in the variety aspect of big data, requiring new thoughts on architecting secure systems. And you bring up a very good point, where architectural thinking is very, very necessary, not only at the level of a single organization, but as a whole of what is going on throughout the internet. Because, as you said, you can aggregate data from various endpoints, and suddenly you have a much clearer picture of sensitive data than before. It's unclear, at this point, how you can ... So, technologies like differential privacy, they have a privacy budget, which is that you always leak some amount of information, even if you aggregate it. And if you do that too many times, then the privacy budget is lost, which means that over time, you get clearer and clearer, more and more accurate picture of the sensitive data. So this is kind of inevitable. So, other than completely restricting access to the data, it is not clear how to stop this leak of information.

Dan:                Where does anonymity ... So, in order to guarantee some degree of privacy, you tended to lead towards systems that identify the players ... You mentioned anonymity at some point. How are you dealing with anonymity, and are we trying to solve for anonymity?

Arnab Roy:          So, for our document, we just describe what the problem is. It's not a solution document. But in the research community, there are technical aspects to ... So, I talked about how do you reconcile authentication and anonymity. So that is a technical question that the research community has been looking at. So there are primitives called group signatures, for example. What does group signature mean? It means that you have a group of people, and anybody can sign a message, but you won't know who signed it. So you can still authenticate that person. But you will not know, beyond the group structure, who that person or entity is. 
                    So you could say, you know, give them the same signing. But that is not desirable, because later on, there might be an arbitration process, where you want some amount of non-repudiation. You want to hold that person responsible if a legal case comes up, for example. So that's why this kind of primitive is far more sophisticated than just giving out the same signatures to everybody. So this system, in fact, allocates a trusted arbiter who has some more information, so that he can look at the signatures and identify who signed it. But without going through this arbiter, nobody can find out who signed it. So that is one of the technologies that addresses reconciling authentication and anonymity. And you can think of it in an IOD context as well. There are different IOD devices; you don't want to specifically pinpoint which device it came from, maybe that's very personal. But if there is a glass-breaking scenario, you want to know.

Dan:                Yeah, the concept of trusted arbiter I think will come in handy as we model things up, yeah.

Mark:               One of the approaches that came up ... As Arnab said, we don't really get very prescriptive, but we talk about trying to treat PII, and what PII is varies depending on the domain. It could be a floating point number, depending on the scenario, right? But if you have a domain that you can consult to understand the meaning of a thing, you might want to tag that data throughout a system. And that includes when you federate the data. So the persistence of, some people call this metadata, but really it's just carrying other data along with it in some kind of structured framework so that you can do traceability and provenance, so you can understand when it's been violated. So that's kind of the fundamental principle, and doing PCI compliance or being HIPAA-compliant, which is something most of the big companies we're in have to do on a regular basis.
                    But the problem is there for everybody really, because if you think of PII as just an instance of really, really important data in some domain, then that's an issue we all face at some level. And from a security point of view, you want to know that you can expose where that data's been used if you need to, and who's touched it, and to authenticate the people who've done the touching. And that includes machines. And that's why, I don't know if you were there, Dan, when you were trying to get booted up, I was touching on this issue of authenticating these low-cost smart home devices.

Dan:                No, I wasn't no.

Mark:               It's an interesting use case, and stop me if I already mentioned it to this group, but anybody on this call have them at home already?

Dan:                I've got an Alexa.

Speaker 4:          [inaudible 00:48:00]

Mark:               Do you have any smart switches tied to it?

Speaker 4:          Yeah, yeah.

Mark:               So, the smart switches are mostly going to cloud service overseas, written by who knows who, in fact. In fact, the air messages that come back are in Chinese. You see the Chinese stuff at the top, and then ... So, this is an interesting problem, we have a cloud service from Amazon doing the driving; a local IoT device, i.e. Alexa, on your home network, probably on a single segment, collecting data for Amazon, but going out to these other cloud services to direct traffic out to these devices. And if you roll this into a neighborhood or utility scenario, it's an interesting problem, which kind of is part of the rationale why we're glad, in retrospect, that we stayed away from the more expansive cloud-specific model, because this is more realistic, I think, this multiple cloud, multiple entity, multiple developer communities, even. So it's more of, I guess, a case study than a use case. But it certainly is a realistic one, at least in my house.

Dan:                Absolutely. And you can, you know, drop a 3G chip in there and easily back-channel some other data source.
                    Good, well, let's keep on topic. So, I want to give everybody a time check. We've got five minutes here to wrap up. Any other questions for Dr Roy?
                    All right. So, thank you, Dr Roy for sharing. This has been insightful. Look forward to integrating and capturing these in our notes, and Mark, I added to my rolling agenda a check-in from the NIST Big Data Working Group. If there's nothing to report, please just feel free to ignore, but would love to have you share, at the beginning of our meetings, any context or any information that this group would find relevant. I'd really appreciate the perspectives that you're bringing.

Mark:               Sure. Let me do that, since you invited me, and I'll make it short, in light of our time.
                    I introduced ... This was me dominating the last conversation we had in that group. We were trying to understand how to do traceability for ethical requirements that are put out in organizations, and it's a big data problem, because often these things are authored by people outside the organization. Or inside it who the developers are not connected to. So, to some extent, it's a traceability challenge; it's also a problem of: where do the natural language artifacts belong, and what do you do with them in the architecture of the systems you're building? So whether it's a cloud native issue, it's certainly one that we're wrestling with, and if you think about some of the uses for algorithms that are being contemplated or have already been deployed, sooner or later, we're all going to be in a position of having to explain algorithms and why they are recommending one thing or another to users. So we're trying to figure out what the implications of all that are and if we can make any contributions.

Dan:                Nice. Yeah, that's a big area that I'm happy to hear you're trying to get out in front of, because not a lot of folks are getting out in front of that, and that's barrelling forward.

Mark:               I'm afraid I'm going to be in a position of that poor [inaudible 00:52:24] logging engineer, who ended up getting blamed for it on the [inaudible 00:52:30].
                    Right? Right.

Dan:                Exactly. That's a great perspective of how that ends up playing out, and the individuals that get the real hit for bigger decisions like that.
                    So, coming up, I've got Geri, who unfortunately couldn't join us today, she had a sick kid to take care of, is going to be joining us for an overview of some of the security infrastructure that she's been working on at CyberArk that overlaps the Kubernetes and Cloud Foundry deployments of cloud native infrastructure. So looking forward to that. I think next week we'll have ADP lined up. And then June 1st, I am canceling the meeting. I'm going to be on the road and in Berlin, so in a couple of weeks we'll give you a Friday off to enjoy Friday things. All right? Thanks everybody. Thanks for joining us. See you next week.

Mark:               [inaudible 00:53:59], everybody.

Speaker 5:          Thank you, bye.

Arnab Roy:          Thank you.