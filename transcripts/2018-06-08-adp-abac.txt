Dan:                [inaudible 00:00:36]

Michael:            Hey, Dan.

Dan:                How you doing?

Michael:            Good, how are you?

Dan:                Great. So, I'm in Prague and I just got finished hosting a working group and my WiFi was iffy, so Sarah Allen is going to lead the facilitation.

Michael:            Okay, cool.

Dan:                Nothing really changed much for you, just so you know.

Michael:            Yeah.

Dan:                Hey, Sarah. Speaking of the devil. You're muted.

Sarah Allen:        Hello.

Dan:                Hi. Michael's our presenter.

Michael:            Oh, am I the only presenter?

Dan:                So, I have someone that was slated from about a month ago lined up for today, but Jerri hasn't been on the last couple of weeks, and I haven't received a confirmation from her. So if she shows, it's her slot. But if she's not here, then we-

Michael:            Then I would kill her.

Dan:                Yeah, then the fact that you're enthusiastic to get it in today is really fantastic, because it potentially lines that up.

Michael:            Sure, awesome, thanks.

Dan:                You bet.

Sarah Allen:        So, I just added the notes to the calendar invite.

Dan:                Awesome, thank you. Jerri, hi. You're muted.

Jerri:              Are you relieved that I've come?

Dan:                Yes, though I wanted to sanity check with you before we went live. Are you ready to present today? I haven't seen you in a couple of weeks, but I wanted to have you slated for today.

Jerri:              I'm ready.

Dan:                Okay, great. Awesome. So Michael, this is the priority. Sarah, I recommend, if we end up filling time, then we prioritize that and not try to squeeze both sessions unless it lines up that we are making a good use of time.

Sarah Allen:        So when you said this is priority?

Dan:                Jerri is priority. She was on the schedule. Michael asked if it would be possible to present today, and I said that we'd have maybe 20 minutes. And Jerri, one of the reasons why I'm managing expectations so much is I'm in Prague and my WiFi has been really poor. And the last session that I was facilitating, I was dropping a lot. So, Sarah's going to be facilitating today.

Sarah Allen:        But you are recording?

Dan:                I am recording and...

Sarah Allen:        So both this [inaudible 00:05:23].

Dan:                And I don't know any other way to do that.

Sarah Allen:        Or I don't know if there's some way for me to take over record.

Dan:                I can do cloud recording maybe.

Jerri:              I have a record button on my screen. Is it possible for anybody to record?

Dan:                Go for it. If not, I can probably upgrade your capabilities. I think you need to be a co-host.

Sarah Allen:        It's request, oh, wow. Jerri is the co-host. All right.

Dan:                And now I think you should have the privileges. So having a backup recording would be great.

Jerri:              Okay.

Sarah Allen:        Thanks, Jerri.

Michael:            Yeah, even if there's just like two minutes Dan, then I could just point people to the [inaudible 00:06:16] and then, we're going to put our image online. And so, we're just trying to get the word out and get people more of an understanding of what Falco is and what it does and how it can help in the security space for Kubernetes and Cloud-native apps.

Dan:                Excellent.

Sarah Allen:        Great.

Dan:                Yeah, we have to provide a platform for that. So, Jerri, I... Oh, I see you're recording, so yay.

Sarah Allen:        And I'll volunteer to scribe. Is there somebody else who's willing to take notes? Michael? Christian?

Christian:          Sure, I could do it. I'm one of the usual suspects, right?

Sarah Allen:        Yes.

Christian:          Can I have the link? I don't have the link.

Sarah Allen:        I added it to the meeting invite. I will also add it just-

Dan:                Okay, don't worry. I can find it.

Sarah Allen:        So, I just added it to the chat. So yeah, and anybody should feel free to like add in notes. I added the people that had names in the participants, but please feel free to fix your name if I spelled it wrong, and add your affiliation and any links or anything. Do we have any other orders of business, Dan? Or should we just dive in?

Dan:                Yeah. Doug, are you dialed in? Someone's dialed in. Doug Davis of IBM. There's check-ins for the [inaudible 00:08:47] working groups, and I did ask Doug if he would share a bit of context from the TOC meeting.

Sarah Allen:        Oh, great.

Dan:                Right? If Doug's not here, since we have a full docket, I think we should probably go ahead and get started. I can fill in a little bit of my interpretation of that, of what happened. So, a couple things were happening. So, the Cloud Events project, Cloud Events is graduating out of the server-less working group. One of the discussion points that was highlighted was that that working group elevating itself to having code was seen as the best way to engage in the CNCF. So, I was very, yeah, I did one of those-

Sarah Allen:        But it doesn't have code. It has a specification and the working, I'm part of that working group.

Dan:                Oh, I know.

Sarah Allen:        And people have done, there was like an inter op demo, but the group has not produced code. So, one of the things that I was very intrigued about was, I thought that CNCF projects were all code-based. And this is the first time there's been a project where the goal of the group is to create a specification, and it's kind of an open question. I think there's a lot of interest in creating shared libraries, but there has been...

Sarah Allen:        I haven't been actually attending the meetings for a few weeks, maybe a month. So, things might have changed a little bit, but I hadn't noticed, I hadn't seen notes that it changed but, yeah. So, there was kind of an open question whether it would be like lots of people doing separate interoperable libraries, more like IETF style where there's different implementations that inter operate, but just kind of what we did with the 01 specification. Or whether the group would get together and build software together. So, yeah, so was there discussion of that at the TOC meeting?

Dan:                Here's Doug.

Sarah Allen:        Great. Maybe Doug can speak to this, because I haven't been at the meetings for a while.

Doug Davis:         [inaudible 00:11:21]

Dan:                Welcome.

Sarah Allen:        We were just talking about Cloud Events graduating from being a project of the working group to being it's own sandbox project.

Doug Davis:         Oh, okay.

Sarah Allen:        Dan was saying that it was worse, because it had code. And I was saying, that I think it was, to my mind, the first thing that had become a sandbox project that didn't have code. Maybe Doug, you can speak a little bit too.

Doug Davis:         Yeah, we wrote a whole web rotation while you were gone. No, actually, no, you're right. It does not have code as of today. The closest I've heard about us having code is we've heard some discussions around possibly some shared libraries or shared coding efforts around some shared libraries and stuff, but it would actually become part of our working group. Or we just have pointers to a common opensource projects... talk about [inaudible 00:12:18].

Doug Davis:         I did think it was weird, but during the call, I think it was Alexis made a comment about us having code. And I didn't correct him, because I thought it was just off the company market. I didn't think it was worth diving into. I didn't quite understand what he meant by that, to be honest.

Sarah Allen:        It may be that the inter op demo was mistaken as code that the group had built together.

Doug Davis:         Maybe, yeah, maybe.

Sarah Allen:        I don't know.

Dan:                Okay. So, it sounds like we don't need to over-index on that thing. In fact, that was Doug's feedback to me when I [inaudible 00:12:56] to talk about this. Great. Okay. So, that was the, there's that discussion, and then, there was an interesting discussion around projects that are only associated with Kubernetes, and whether they would be appropriate in the CNCF. And there was a fair amount of debate there.

Dan:                It was fun, for me, since NOYES Foundation was referenced a lot since we in the foundation chose not to integrate and support UserLAnd projects inside of Node, and that was just scale and scope. The scope of supporting and integrating, choosing which are the blessed UserLAnd projects that we choose to support inside of the NOYES Foundation which was created to sustain the NOYES Project, was something that we could not sustain within the structure of the NOYES Foundation as it stands. So that's tangential to safe, but was generally interesting. I thought the first half of this weeks TOC meeting was quite interesting. If you have the opportunity to go back and give it a listen I recommend that.

Sarah Allen:        Thanks, Dan.

Dan:                I don't know if there are any other check-ins from other cities and working groups? Okay, you should get started.

Jerri:              So are you ready for me now?

Dan:                Yeah, do you want to kick it off Sarah?

Sarah Allen:        Jerri ... Jerri ...

Jerri:              Yes, okay. I'm going to share my screen.

Sarah Allen:        Great.

Jerri:              So let me know if you can see it.

Sarah Allen:        I can see it.

Dan:                Good.

Jerri:              All right. So at the time that I proposed giving this talk I wasn't really sure what made sense for the group, but what I've decided to focus on is just what our experience was integrating our service with both Cloud Foundry and Kubernetes. I will get started, I have a little overview of what we did in each piece, and as part of that overview I'm going to touch lightly on things like: how we determine application identity in each of these systems, and in each system how the system API's can be leveraged to perform some of the tasks that were required, which is probably indicative of the fact that those API's should be designed with fine-grained commissions so that we can preserve the principal of this privilege in that kind of a situation.

Jerri:              The first case I'm going to talk about is our integration with Cloud Foundry. Both of these integrations were customer-driven, where we had requests from some of our enterprise customers to make it easier for them to use our product on these platforms. The first customer request we got was for Cloud Foundry integration, so that's the one that I'll talk about first. And as we started to investigate what that integration looked like very early on, we discovered the concept of a service broker.

Jerri:              So what is a service broker? Most of the time if you have a service that you want to list in the Cloud Foundry Marketplace, you're going to need to create a service broker. Marketplace is a listing of all the services that are available [inaudible 00:17:25] look for services on there. It's a great way to make sure that your service is visible and easy to use for developers. So the service broker is just basically an application that you also do [inaudible 00:17:36] Cloud Foundry, and it has a handful of API endpoints that list the service offerings that are available that allow you provision an instance of your service, whatever that means for your service, and that delivers credentials to access your service to the application. You basically just need to implement a few endpoints, and then you can have a service broker. The service broker has to conform to the open service broker API standard, and that standard has been accepted for use in Cloud Foundry, Kubernetes and OpenShift to [inaudible 00:18:17]

Jerri:              On the last slide was sort of the [inaudible 00:18:26]. I guess I would like to just show a graphic about how this works. So you have your external service. You have your Cloud Foundry installation. You deploy the service broker application to its own organ space to seal it off because nobody, except your admin, would need to access it directly. You create an organ space for your application to be deployed in, and in that app organ space you would create a service instance, and creating that service instance is that provision step. That communicates with the external service and does everything that needs to be done at that step. Once you're ready to deploy your application, the application will bind to the service instance and communicate with the external service to get credentials to access that service.

Jerri:              What I showed on the last frame was step two on this screen. This is from the Padiddle Cloud Foundry documentation. There are other ways to integrate your service in Cloud Foundry. Levels three and four both involve the service being deployed directly to Cloud Foundry, which is something we haven't explored yet. Then there's sort of standard ways that you might interact with an external service, like just providing the database credentials the usual way instead of worrying about the service broker. That's sort of the possible scopes of doing it in Cloud Foundry.

Jerri:              Having said all that, I'd like to just take a second and look at specifically what our does. So I work for CyberArk on the Conjur team. Conjur is a secure vault that people use to secure credentials required by applications. Applications use these credentials to connect to databases or API's. So if you have an existing Conjur installation you want to deploy some apps to Cloud Foundry, you'll install our service broker, and we also created a build path to make it easy to inject those credentials needed by the application into the app. When you deploy your application you're going to bind it to the service broker, which gives you credentials to access Conjur, and creates an identity in Conjur for the application. You update the policy within our service to grant access to the credentials that the application needs. And then when the application starts it uses those credentials to get the access keys that it needs to access other services.

Jerri:              So that was our Cloud Foundry integration. Shortly after, maybe even during the time we were working on that, we started getting a lot of customer requests to integrate with Kubernetes. In the next few slides I'll talk a little about what that looked like. It ended up being quite a bit different from the way that we handled things in Cloud Foundry.

Jerri:              So even though Kubernetes officially supports the use of service brokers it's still in pretty early stages, and if you actually look at their coding dead hub it hasn't actually had a stable release yet. It's probably not something that is worth trying to use in production at this time. Instead of doing the same kind of model that we did in Cloud Foundry, we decided on a completely different attack. One of the big differences is that in Kubernetes we facilitate deploying our service to Kubernetes as a high availability cluster. Then our service has a special authentication plug-in that is specific to Kubernetes, and each application is deployed with an authenticator container that interacts with our service and delivers a time-limited access token to the application so that it can authenticate with our service.

Jerri:              This is just a graphic of our workflow. What happens is the authenticator container that's deployed with the application starts out by submitting a certificate sign-in request to Conjur with a Stiffy ID with the pod information contained. Conjur responds by injecting a time-limited certificate into the pod using the Kubernetes API, using that pod information that was included in the cert request. Then the [inaudible 00:23:21] the certificate and that authentication process results in a time-limited token being placed into this shared memory. So now the application has access to a time limited access token in the shared memory, and it can use that token to retrieve whatever information it needs from the external service and initiate that connection to the external service.

Jerri:              So I'm hopeful that this kind of a model might be something that other services also find useful or that the way that we've implemented it means that external services would actually be able to use the application identity we provide in Kubernetes to authenticate Kubernetes deployed applications themselves. I'm curious to see where this will go. Right now it's only available for Enterprise customers, because it is still in that open source to be released at the end of the month. That open source release is going to include both the custom authenticator that we use, which is specific to our product but could be a good model for other products, and the authenticator container, which is deployed together with the applications.

Jerri:              Having sort of covered what we did both in Cloud Foundry and in Kubernetes, there's one last thing I would like to talk about, and that is the developments that have been happening in Cloud Foundry since we created our integration there.

Jerri:              Since we did our Cloud Foundry integration, Cloud Foundry has released something that they're calling "app instance identity" which just basically means that every instance of every application deployed in Cloud Foundry is deployed with a X509 cert and a private key pair that encodes its identity in the CF deployments. It has information about the application grid, the instance grid and the org and the space that the app is deployed in. My hope would be that we might be able to change our Cloud Foundry integration to leverage these certificates similarly to how we have been operating Kubernetes.

Jerri:              In our Kubernetes integration we basically turned Conjur into a certificate authority for the Kubernetes deployed applications, and configured Conjur to accept the Conjur generated certificates as proof of identity via mutual TLS. We might be able to modify our existing Cloud Foundry integration to work in a similar way, to have an authenticator build pack is probably how it would work that would take on that role of communicating the custom Cloud Foundry authenticator to inject time limited access token into the application memory.

Jerri:              Where is it now? It's not yet Spiffy compliant. I expect that they may be working on that though, and that may change, and they're working on improving the specs on the workload for accessing the certificates and validating them against the certificate authority. I think this is really interesting. I'm really glad that things have progressed this way in Cloud Foundry, which also led me to the question of how long it might be until Kubernetes also is updated to commit app identity out of the box. We know that Spiffy is currently a sandbox project in NCF. Again it remains to be seen where that is going to go, but it's an interesting time to be talking about application identity.

Jerri:              At this point I would ask if anybody has any questions, and I will do my best to answer them. This was sort of, I didn't try to plan something very in-depth or low-level. If there are things that come out of this that people would like more information about or would like me to dig deeper into at another time, I would be happy to consider doing that. I don't know if people have a way to get in touch with me ,but I'm on GitHub so my information is there.

Sarah Allen:        I think we're all also on the calendar invite, and if anybody's not on the calendar invite ping me or Vin, Matthew, or JJ.

Jerri:              And I will definitely add a link to these slides, a PDF of these slides, in the minutes so that if people wanted to go back and refer to them they could. In particular, I have this note here that if you're curious about looking at the code for what we did for our Kubernetes integration or for the Cloud Foundry service broker or BuildPath, it's all publicly available, or will be by the end of the month. We'll announce the Kubernetes on our website, conjur.org so that would be a good place to watch out for it.

Sarah Allen:        Great.

Dan:                Awesome.

Sarah Allen:        So had just a question, like you called out that this notion of instance identity and if that were actually a thing that was consistent across platforms that seems like a very clear opportunity, and that it would have made some of the work easier or at least you could have leveraged this work perhaps across the platforms. I'm wondering whether there's anything else in the sort of aspect of secure access where you had to maybe implement stuff in application logic or you saw things in one platform that you wish were more ubiquitous and if you could kind of speak to those challenges and opportunities.

Jerri:              To have a consistent way to identify applications no matter which platform you were in seems to me so valuable. We're one service, but there are other services out there that are trying to do the same kind of thing. Hibital has a great relationship with the people that add services on their platform, and through them I've encountered a lot of other people trying to do this kind of work. I think everybody would be glad to see a secure and consistent way to validate the identity of applications. One other thing that I really only lightly touched on, but I think is really important too, is making sure that these platform-level API's, so in Cloud Foundry it's the cloud controller API [inaudible 00:30:20] you really want to design them so that you can give granular access so that you can provision a service account that can only access certain routes or as granular as you can make it so that if I want to develop something that could use that API. For example, I want to validate that there really is a pod in a given mean space using an API. I don't want to have to give that service account really expansive permissions to be able to do that.

Jerri:              I want something that I can just allow it to ask this one specific question that I want it to ask, and then not give it any other permissions so that if somebody were to somehow get those access credentials that the service account has, they're not going to be able to go very far.

Christian:          So, sorry, hopefully my connection comes through. So Jerri, one thing I wanted to, since you are presenting, I wanted to make sure you saw in the chat that Doug is the co-lead of the open service broker API specification.

Jerri:              I did see that, and actually I just yesterday finally got my legal department to approve me as a contributor, so I have a [inaudible 00:31:54] open.

Christian:          Nice.

Jerri:              And that contact that I need to go back and review now that they finally, it's been months, it took them a very long time to approve it. I will be doing that probably in the next two days.

Christian:          Cool.

Jerri:              Thank you.

Christian:          Beyond that I had a question, you know in addition to Kubernetes and Cloud Foundry, are you looking at supporting any other platforms? Are you supporting a platformless, you know, not one of those too?

Jerri:              So we do have other stuff, for example, we do have a custom authenticator for IM, and then we have a workflow that we call Host Factory that people use with they're deploying like BM's to AWS. I don't know that an implementation as specific as one of these would be required from most other workflows, it's one of those things where when it comes up we'll know it and we'll have to deal with it, but it's not come up right now. A lot of our more general tooling has been workable for a lot of different systems.

Christian:          Mm-hmm (affirmative). Mm-hmm (affirmative). Well the reason why I ask is just, I think that's great perspective knowing those use cases where folks have things that go outside of the Cloud native workflows and being able to validate the approaches that we have in that non sort of Cloud native blessed cases is I think interesting to our work.

Sarah Allen:        Jerri, you mentioned that custom authenticator for IM, is that AWS IM specifically?

Jerri:              I think that's the focus at first, but I'm hoping that it will be more general. We have customers that use GCP, we have customers that use Agere. I'm sure we'll need to address all of those cases. Well thank you for giving me the opportunity to talk about this, it was fun.

Sarah Allen:        Does anybody else have any questions?

Michael:            I guess the only question I would ask, how would you compare it to Vault and what Vault's doing with Open Service Broker? [inaudible 00:34:20]?

Jerri:              So I know that Vault has a service broker. I don't know how much they're doing with that or how it's being used. I do like that our solution also has the build pack, which makes it easy to inject the secret values into the application at one time because it installs Summon, which is our tool to do that. So I do think that's an advantage for what we've done, but in terms of having a service program, I'm sure it's very similar.

Michael:            Okay. So then you you have to end up building something like Summon to get the secret from Vault at one time and then just-

Jerri:              Because they don't have summon, you're probably like modifying the code in your application to use a client library or something like that. Summon just puts the values in the environment of the running process.all right, well thank you everybody.

Christian:          Thanks Jerri.

Sarah Allen:        Thanks Jerri. So I don't know if Dan has connectivity, but we can, it looks like we have time to have Michael talk about his use case and project.

Michael:            Nice. Sorry, my wife just asked me if my son can do piano, and he's right above me, so I had to tell her no. Let me just share my screen. So I'm not sure how much everyone knows about Sysdig. Sysdig started off a company with an open source project that focused on capturing system calls. So easiest way to think of Sysdig is [inaudible 00:36:30] dump for system calls. So what we can do is we can look at a Lennox based system and we can see all the system calls that are going through it, and then capture those system calls into what we call a SCAP file, and then that SCAP file then can then be used to go back and see what was happening on the system from a system call perspective at that time. So what we did is we took that same similar concept of capturing system calls, and we wrote a rules and gen around those system calls. That's really what Falco is. So it allows you to detect abnormal behavior inside of those system calls. We specifically have focused on container based systems, although it will work for any Lennox based system and it is Lennox only right now.

Michael:            This is kind of where the market is starting to define this term, what we call Runtime Security. We're definitely not the only one's in this space of runtime security. There's other tools out there such as Twistlock and Aqua, Fresh Tracks also does some things around this as well, and there's one other I think, Stock Rocks as well. This is starting to kind of become this more versioning space around Runtime Security. We're the only ones that offer a open source solution to Runtime Security, and we also offer a proprietary version of Falco as well that gives you a lot of features out of the box. What this abnormal detection can do can detect things like shells or processing [inaudible 00:38:10] inside of a container, unexpected outbound connections. So all of a sudden your database container starts making outbound connections to the Internet, that would be something that would be abnormal. Processes start listening on ports that you don't expect. Binaries being changed inside of a container and so forth.

Michael:            The way we want to look at this from a security perspective is while we can do things in the image build process using a notary and image scanning to make sure that we're not shipping things with vulnerabilities, or we know what we're shipping inside of the container. When the container actually launches, most container runtime environments are not immutable. So containers can then make changes to their environment once it's up and running. So installing new packages, modifying things and so forth. What Falco allows you to do is that when we detect this abnormal behavior we'll notify you. That notification is up to you to determine how you want to process it.

Michael:            So why do you need it? The Cloud native paradigm really gives you a lot of choices. It pushes choice down to the development teams, right? Developers can package up their application inside of a container and let's just say you don't always know what's inside of that container that development team has packaged up and want to deploy to your production environment. Image scanning is seen more as a point in time, so when you scan the image you know the image doesn't have any vulnerabilities, but when the container image actually goes to production, there's a lag time between when you scan that image and when that container image is actually running. As I mentioned, running containers aren't necessarily immutable unless you specifically have them running in that way. The resource isolation paradigm of containers is much different than BM's and we see this as a need in the market when you see things like Devisor and product container as well, that have come around as well that seeks to provide more VM like isolation for containers.

Michael:            And so what Falco can detect is vulnerabilities and things like container isolation, exploited applications, things like exposed dashboards or exposed API ports where all of a sudden images start getting launched that we don't expect which the last one exposed dashboards and API ports is kind of a common thing if we think back to the Tesla hack, it really wasn't a hack, Tesla just left their Kubernetes dashboard wide open on the Internet. And also what you can do with Falco is begin to enforce best practices around things like CIS, PCI SOX, and everyone's favorite GDPR, as well as organizational security best practices.

Michael:            (silence) is to sort of function inside of the kernel. It uses something called Tracepoints inside of the kernel, and then we have an alpha, an early alpha version of an EBPS probe that can be loaded up as well. That has limitations of course, you need to be running a newer version of a kernel in order to take advantage of that, and it needs to have EBPS support built into it as well. So for those of the people who aren't necessarily comfortable with the kernel module level of integration, then we can do it with EBPF as well.

Michael:            Then this basically the stream of system calls will come into the processing libraries and be a vent engine that is then, rules are applied to that [inaudible 00:42:19] as far as alerting is concerned. So we can log the sys log, we can log [inaudible 00:42:29] files or we can execute a program. That program could be something that then goes and posts to a webhook or something like that. What we want to try and do, and what I, we're actually presenting Falco as a potential sandbox project at the CMCF talk, is that we see a lot of possibilities that if we could have other event streams where we could take this rich rules engine and apply these rules to these other event streams. And then also having more generic notification providers as well so that we could hit a webhook natively from Falco, if we could push to something like a messaging system like Nats or something like that natively inside of Falco as well.

Michael:            So that we can kind of be this rules engine and then from a modularity Cloud native perspective we can have other event streams that are actually sending us data that we're processing.

Michael:            A little bit about the project and growth of the project. We're actually seeing lots of usage at least from a downloads perspective and docker helpfuls as well. So we're well over three-quarters of a million docker helpfuls for out images. About 34,000 downloads of the actual RPM's themselves, and of course everyone loves GitHub stars so we're about 805 GitHub stars as well. Users of note, so Lyft has used us for awhile and we're in the process of trying to document that story from them. But another great one is cloud.gov, so cloud.gov, and by the way, this presentation is linked in the [inaudible 00:44:18] that I opened to do the presentation, which is in the notes for this meeting. But this right here is actually cloud.gov's documentation that actually talks about how they have this behavioral monitoring in experimental mode right now in their Cloud Foundry environment for cloud.gov.

Michael:            And then they've also given a presentation at the Cloud Foundrey Summit as well about detecting tainted apps using Falco inside of Cloud Foundry as well. So it's not just something that can work with Kubernetes, it is something that can work with Cloud Foundrey as well. And so I'll kind of let you look at the rest of the presentation on your own. Is there any questions and I can just give people a quick demo and just show how it works very quickly?

Sarah Allen:        A demo would be neat.

Michael:            Okay. There's also a good presentation, which I can drop in the document, or in that meeting minutes as well. There's a good presentation around runtime security that Google gave at KuCon EU just a few weeks ago. It kind of lays out what are the areas of security that you need to worry about, and kind of defining what the space of runtime security is and what runtime security means and how it's different from supply chain security or infrastructure security. So let me stop and share my entire screen. All right. So what we have here is I have a bar in my way. So in this environment I've got a couple different things up and running. So the main thing is is that we have Falco up and running here. This is deployed as a daymon set. We provide a daymon set for users to actually quickly deploy this. All of the configurations for Falco is stored in a configuration map on this daymon set will then pull down that configuration. So all of your rules and things like that would be stored in a config map, and then those rules are pulled down when the container launches or the pods launch it.

Michael:            The other thing that we have in this environment is NATS as well, and so NATS is acting as out messaging platform, and what Falco will do in this demo is it will push an alert over to NATS and then we have Kubolos running as well. And what Kubolos is set up to do is it's set up to listen to a particular topic or a subject in NATS, and when it detects a critical alert it will actually go and take action. So let me show you what the rules actually look like. So in [inaudible 00:47:29]. The rules use a pretty simple language. It's the same language that we use for Systic, and what this looks like is you basically just have the field and then some value and the you can string it together with other values as well. There's lots of different [inaudible 00:47:52] logic that you can do inside of the rules as well. The other thing that you can do is you can key off of Kubernetes metadata as well, so Falco will connect to the Kubernetes API server and pull that information back. So you can say for this particular application that's running in a certain name space with a certain Cloud name with a certain label, I want to be able to take action on it.

Michael:            [inaudible 00:48:15] KryptoMinor is running inside pf Kubernetes, so we take the load front end application and if I spot a process and I'm in a container, so basically I'm not running on the host system, and my command line contains Stratum TCP, which is a common protocol that's used for minors, then I want to throw this alert.

Michael:            Another example is you can list out all common minor ports in this case, and if I see a front end application making an outbound connection to a minor port, then I want to throw a critical alert as well. So you can see the rule language is actually pretty flexible, it's also fairly simple as well. Also what we have is over in the Kubolos side of things, we have a very simple function that basically says if I see a critical alert and I'm not running, I'm running inside a container, then I want to actually take action on that. What this will actually do is that if I detect a critical alert running inside of a pod in Kubernetes, it will actually go and delete that particular pod. Any questions before I run this real quick? So this is a no-

Christian:          I have a quick question. How is this secure? Can anybody else inject a critical alert and use that for [inaudible 00:49:54] on a pod?

Michael:            Yeah, so the way it would be secured, at least in this particular case, is that you would have security on that so that only certain people could actually into that. The other thing is people would have to get access to the particular host system and they wouldn't necessarily easily be able to spoof that it was coming from a particular container, because you have to be inside of the container, and then were actually looking at the system calls themselves inside of the Lennox kernel. So you would have to somehow spoof the system calls to say that it's this particular process is being ran from a particular container.

Michael:            The other thing that you can do as far as NATS is concerned is of course use TLS so that you're making encrypted connections into NATS as well so that people can't easily go and see what's being sent, or if you're using mutual authentication then only certain people being able to connect on that server. But if somebody's able to get to the host system and spoof this, and de-DOS this, then you probably have worse case, you probably have worse situations going on in your environment. If somebody's able to get to that host system and spoof it. Does that answer your question?

Christian:          Yes, thanks.

Michael:            Yup. So the first thing that I'll do here is I'll go and connect to, let me just pull this. So I have a no JS application up and running, but since Dan's on the phone, I didn't know if it was appropriate to remotely exploit it.

Sarah Allen:        Sure, go ahead.

Michael:            So let me just jump onto this front end machine real quick. I need to pass flags. And so the first thing I'll do is I'll just run a batch terminal on it. Oh, sorry. Of course when you dunk the demo nothing starts working right. I need to specify my name space, and there we go. So you see right away that I've opened a terminal and I get an alert right here over in this Falco pod where I'm tailing logs. And you can see that I've opened up shells. So a shell will respond inside of a container with an attached terminal. So some of these went interactive inside of this container. So what I can do now is I can run something that will actually trigger the alert. So let me actually go over here and see if I can get this to work. It wasn't working earlier via the remote exploit. Let me see if I can get it. And so this is actually sending a profile cookie, this profile cookie is actually encoded, and this application doesn't actually sanitize the inputs from the cookie. There's a way that you can actually exploit Java Script by doing, it's essentially a form of Just In Time execution that you can inject functions [inaudible 00:53:22].

Michael:            Application was poorly written and somebody's not sanitizing the inputs. And if I click send, let's see if it works. It didn't work, so let me go over here and let me just do it this way. So I'll just do a curl, and remember that rule that I had open that if I had Stratum TCP in the command line, it would through a critical alert. And of course my demo doesn't work. But it should actually go and kill that particular container and shut it down. And of course I tested it before I got on the call and it worked fine, but it should've shut that container down, but you can see that it is [inaudible 00:54:21]. Then hello, I get an alert right there that I modified or I've created that new file. If I did something like [inaudible 00:54:34] I get an alert right there as well that I'm modifying things in the binary directory as well. These are all kind of common things that you would expect somebody whose getting into a system to do as they're trying to compromise a system.

Michael:            So with that I'll ask if there's any other questions for anyone?

Jerri:              I have a general question. I may have missed the context for why we're talking about this [inaudible 00:55:13] to talk about that a little bit more.

Michael:            What do you mean context?

Jerri:              So, and you can feel free to throw this back at me and say I did a bad job of this too, because I think I might have.

Michael:            I might have did a bad job of explaining.

Jerri:              So it's the secure access for everyone working group. So [inaudible 00:55:40] like what is, how does what we're talking about really to the charter of the group?

Michael:            I would throw out there that it may not necessarily take care of the access perspectives of things, and the authentication perspective of thing. I was actually under the impression that the working group was more focused on Cloud Native security in general and how you solve that problem of Cloud Native security in general. And if I'm wrong then I wasted everyone's time.

Sarah Allen:        Well actually I think we're also working to tighten up our charter so that's it's clear to newcomers. What I wanted to ask is kind of related to this. So what we're really seeking to do is kind of figure out is there a common or maybe a few common secure architect? What are the things that if you are coming to setting up a Cloud Native deployment, what do you need? What are the things that every Cloud deployment should have? What are the patterns there particularly with regard to solving these problems where different Clouds have to inter operate and there's kind of a complexity in hybrid systems. And so I'm curious in this work you're doing, which you made efforts to make it work in Kubernetes, not in Kubernetes and different places, are there some things that you are seeing in patterns that have made it easier for you to build something that works in multiple environments in the Cloud and are there areas where you've had to kind of fill in gaps and do things that are substantially different in different environments where you kind of wish there was a little more commonality?

Michael:            Yeah. I think that where the challenges are going to come in from the different Clouds and what we've seen is that it's important to provide context in these security events that we're throwing, and so in this case we're only integrating in with Kubernetes, we can also integrate in with [inaudible 00:57:56] Marathon, but we can't pull any meta-data right now back from something like Cloud Foundry. So when these security events happen, we want to be able to access the API and give people information about it's this particular application or this particular pod, or it's this particular deployment that's actually that's causing problems. The other thing is is that we need API access and getting those API access and authentications to those different platforms can sometimes be challenging. And then the other thing is that if you are going to take action inside of that, how can you limit these functions that are taking action, especially if you are using something like functions as a service or server less functions. How can give them the right level of access to just do that one individual thing that they do without being able to compromise the entire system? And I think that kind of goes back to is it Christian?

Sarah Allen:        Well Jerri brought up that point, but maybe Christian did too?

Doug Davis:         Christian mentioned it earlier right?

Michael:            Yeah, of how do you know the, you're not de-DOSing it and the thing that is taking action is actually taking, it is supposed to be taking action right, and how can you not trick those functions into killing something that it's not supposed to? The nice thing is that if it is (silence), but it is definitely a challenge that we see. I think more broadly and this isn't necessarily a knock against the CNCF, but if you look at the CNCF landscape, security is one area overal, whether it's authentication or runtime security or infrastructure security, that's not anywhere on the landscape whatsoever. There's admittance control, which allows applications. Then there's things like network policy, but I kind of personally feel that security is one of those areas in that landscape that's missing.

Jerri:              I agree. I've actually given the same feedback, and they told me to feel free to add myself. So I don't know if you've added this (silence).

Michael:            Yeah and we've, I've opened up an issue on the landscape to say like where does Falco fit, where does our commercial product fit? And so it's still TBD to figure that out, but as I've talked to some members at the top, they're like well we're not security experts so it's hard for them to kind of digest some of this information.

Jerri:              Yeah and I think that that's kind of, that's part of what we're like trying to help with, right? Is that it's also hard to put just, I don't know, I have missed feelings. Like there are things you need for security, like authorization, like identity, there are these different things that you need that are kind of in there own security world, but everything needs security. So how do we actually sketch out that landscape? I think is one of the questions of this working group. We're not there yet. These use case presentations are a way for us to get common language and to understand the problems that people are trying to solve. So I found this to be really helpful and interesting.

Jerri:              Yeah, I hope you keep coming Michael.

Michael:            Thanks.

Jerri:              I like your perspective added to the group too.

Michael:            Thanks.

Sarah Allen:        So we've just got two minutes left. I think we have a presentation planned for next week, so and I forgot what it is offhand, but we'll send it our.

Christian:          Should we have a presentation about the open source broker as well, I'm not sure if we have that schedule already. It seems to be relevant.

Jerri:              I think that's a great idea.

Doug Davis:         In what respect? There really isn't any security aspect to the OSB API.

Christian:          Oh really?

Doug Davis:         No.

Jerri:              I think there definitely is.

Christian:          The identity seems to have been broken by it for example.

Doug Davis:         Well yes, you can't pass it up identity and yet it passes around credentials, but it doesn' really do a whole lot in terms of helping you with security other than it passes around credentials.

Christian:          All right.

Jerri:              You can talk about how it passes around credentials and whether we can improve that since it has such a big impact on so many platforms right now.

Doug Davis:         Yeah, I guess we could talk about that, yeah.

Michael:            Yeah and I think just more generically just understanding that there's this, the goal is having this generic API where anyone can go and for services and have those services spun up. And then start consuming those services you have to ask yourself how do you restrict access [inaudible 01:02:59].

Jerri:              Doug maybe you can find the person whose thinking about like how do you like issues of trusting services and ditching out access and whether open service broker has all the controls it wants to have or whether the people implementing it are asking for things that maybe need to come from the platforms. Maybe there's somebody who has been focused in developing that area who could kind of talk to how it uses the services and I think particularly key management is kind of a big deal.

Doug Davis:         So I can talk to some of that, but I think I'm going to need more information before I can identify the right person for the rest of the stuff. So what I can if at a future call, of course I don't know when because I'm [inaudible 01:03:49] next week and after that I'm traveling in Asia for a few weeks, but the next time I'm on I could talk about the various data that flows back and forth, how open source booker does it's job relative to credentials. And then from that hopefully you guys can then say okay, here's the problem that we want to talk more about, and then I can identify the right person to talk about that and bring them in. That make sense?

Sarah Allen:        That's great. And I think we have a couple of presentations already lined up, so whenever you are back and free would be fabulous.

Doug Davis:         Okay sounds good.

Sarah Allen:        So I want to be respectful of everybody's time. It's 12:01, so thank you so much Jerri and Michael for your presentations, and please free to review the notes and if we got anything wrong or you want to add color or links I tried to add some links into the notes, but please they are editable by everybody so.

Michael:            Thank you everyone.

Jerri:              Bye.

Sarah Allen:        Bye.

Christian:          Thanks everybody have a good one.