[00:02.200 - 00:06.800]
Hey.

[00:42.900 - 01:14.800]
Can you hear me?

[01:15.400 - 02:07.900]
Great. I'm going back and forth between Hangouts and zoom all morning. And sometimes the audio gets lost. So if you haven't checked in in the docks, please I just off to the docks looking for two individuals really did not do a good job at sort of capturing notes last last session and apologize for that. So looking forward for two volunteers to focus on minutes capturing some minutes, especially as we're getting these use cases. I want to make sure we capture the questions and answers since there will be three key things that will help us build our case.

[02:09.000 - 02:25.000]
Don't know you presenting who's presenting on your side.

[02:33.100 - 02:53.500]
Turner Tim who's presenting today?

[02:54.000 - 03:14.100]
Yeah, I've got two slides cool. You want to test your slides out while we're waiting for folks to log on? Yeah, a couple of us are having issues accessing the dogs. All right, let me give her buddy request for access.

[03:17.200 - 03:38.100]
Google Docs think I've got everything should have open editing while we're alive. I don't even have permission to view it. Yeah me neither. Okay? No. No, it's there. There is an issue that it was close to the group. This is edit anybody in the domain had it.

[03:40.700 - 03:55.000]
All right. Sorry about that. Don't Chinese should have access now foreign.

[04:11.100 - 04:19.500]
So everyone's lugging on I've got in the chat the meeting notes, please add yourself.

[04:42.100 - 04:55.700]
I can I can volunteer to take some great great. Thank you. Appreciate that.

[04:57.200 - 05:01.200]
Could I get someone else to help support torn?

[05:02.800 - 05:05.700]
We're going to still get started.

[05:08.200 - 05:20.200]
Okay, I'm going through and adding everybody in this cumbersome.

[05:23.000 - 05:26.500]
Google Docs process of adding people.

[05:32.800 - 06:32.500]
All right. So continuing with today with with our use cases. We have the OPA use case that we're going to dive into. Thanks again to Shri for sharing the cloud Foundry use case. That was a great discussion and really insightful to get that context. And you know, we had a number of folks who have had the opportunity to collaborate with Opa. And so we wanted to take the full session today to you know, go through the the use cases and you're here bit about the Journey of the that the team behind Opa has been going through and you'll go through some questions and answers so forget to choose got

[06:32.700 - 07:32.700]
Attempt is that you has slides up. Sorry. Yep. All right. So Tim good to get away. Okay, thanks. So so what I thought I'd do is spend a few minutes just give you a quick overview of open and sort of setting the stage there and then and then talking to some little bit about the process that Journey as you say that we've gone through and then and then diving into these cases. I'm obviously that's the meat of the discussion but I thought we should set the stage of it first. And so and so the first thing that that I think the is to mention is just sort of the goal of overwrite the goal logo has always been to make it easy to add Rich policy support to other projects and services, right? That's been the goal. I think of oppas sort of like a library in that sense, but the idea is really that you've got like as this picture shows what we expect to happen have happened. Is it oppas running in a bunch of different places and you know, those oppas are integrated with different kinds of systems like maybe in the micro service case.

[07:32.700 - 08:32.600]
Integrated open with all the different micro services in the running or maybe you're integrating open to different components of kubernetes or into Linux or into all kinds of places and we'll go into what some of those use cases are and what people have found opal useful for but then the idea is that we want to make opal really easy to use and take some 0 runtime dependencies. It's always been when the goal to make it very easy to integrate very easy to deploy and then the idea behind oppa is that is really intended to be something that can make policy decisions for something running right next to it. Right? So we like to think of this as like a host focal kind of Damon that knows how to make authorization or more generally policy decisions for anything that's running on that host. But the goal of Hope is never to has never been to be a service. It's never it's always just designed to be basically a library or something that answers answers questions from services are sitting on the house and so the sort of the sort of management of how you integrate and deal with multiple Opus has always been and out of scope for open so

[08:32.700 - 09:22.200]
You know from my understanding of what safe is is designing to do this this seems like a natural fit for safe. All right, so I think that was the goal. I will skip you some of this everybody here knows roughly what the policy problem is. I'm assuming and so one of the things that open does provide is a declarative language that was designed to work fundamentally with Json data will see some examples in these cases. They're already went through this. It's a library Damon's all written in go. So if you want to integrate as a library, you've got to use you've got to have your system your service written and go all storage of data and policy. All of that is done in memory, right? And so and so having a management piece that is is capable of actually feeding oppa those policies and then you date it needs is people there.

[09:22.600 - 10:03.100]
And we've done a bunch of work around to Lena's while sofa has, you know, a repple an environment where you can go into and run and ask for the results of evaluating ad hoc queries or just running the policy even without having deployed it. There's a test framework for writing unit tests or tracing to do the bug ability. And then we're working on some profiling stuff to look at performance. We are working on standard Library as well so that you don't have to write policies from scratch you go when you pull them in and and immediately you're up and running without even necessarily having to write policy. And then what we're going to do is for the most part focus on a bunch of these Integrations today any questions so far.

[10:06.200 - 11:06.000]
Good. All right. I'll keep I'll keep hammering away. Okay, so conceptually the way that the that opal works is that remember the goal of oppa is to add policy support to an existing project or service and so here we have a sort of a pictorial representation of that. So we have some service doesn't matter what it is. Maybe it's a micro service. Maybe it's kubernetes. Maybe it's casca. And then what you do is you there's an API that open exposes so that that service can ask for policy decisions for enforcement decisions. So the idea is that the service anytime it needs an authorization decision to just it opens up a simple HTTP request and ask sopa for that decision independently. There's a management API that's used for Oppa and through that API you actually provide open with two different conceptual pieces of information one is logic. This is sort of like the policy that you would expect right allow this user to run this API call under these conditions. That's kind of the logic we use Rego. That's the language for expressing that logic and then in addition.

[11:06.200 - 11:49.800]
No, you can you can provide open with arbitrary Json data. And so typically what this data represents is something that's happening in the world. So in the kubernetes cases might be although all the pods that exist or in the in the micro service case, maybe the data is you know, something like your org chart so that you know who's a manager of whom? All right. And so these are the two kinds of apis that open exposes the in particular they're both sort of initiated by by things outside of oppa. So today the service is the thing that initiates the request it says oppa tell me what a decision is and likewise on the management side. There's some external management system that needs to actually push that logic and that data into oppa.

[11:50.400 - 12:36.400]
And so what we end up doing at least for some of the Integrations for some of the use cases that we've done is that we've added a service specific management side card oppa. So for example with kubernetes, what we've done is there's a side card that runs next to Oppa that goes and pulls policies out of the kubernetes API server and pushes them into oppa and likewise that coup sidecar or will go off and grab let's say all of the pods that are currently running a pi server and push that as data into into Obama. And so that's sort of the, you know, the division that we saw earlier, which is it oppa is really intended to be this post local policy engine that makes decisions. That's a completely separate from the management piece right questions about that.

[12:37.100 - 13:36.900]
Yes, I have a question. You you mentioned that you pull the policies out of the communities API server. Are those the armored policies? So do you essentially have an enforcement for our bank policies in Hoopa? Not today? Not today we could certainly we and in fact torn did the did translation of he had a collection of Arbok policies and showed how you could write them in Oka we didn't automate that. It's all a tour and said but but yeah, we've definitely talked about adding that kind of functionality where you could take an existing policy language and then sort of compile it down into into oppas. But what the but what we did do or what exists is called The Coop management. It's in the code management repo within the open policy agent GitHub org. What that actually does. Is it is it cold oppa policies out of a conflict map inside of kubernetes and then pushes them into Oklahoma. So the way that you sort of use

[13:37.000 - 13:47.600]
Open for at least a coup Burnett it for at least a couple of companies use cases is that you write your policy and you push it in as convict Maps Okay, okay. Okay. Thanks. Yeah anything else?

[13:51.300 - 14:50.900]
Okay. So I mention the API is in the last slide. And so I figured especially given some of the interest of this group. It was worth spending a couple minutes just talking about what what apis open supports today to give you a better feel for this. So really there are two kinds of apis it open supports here on the top four are really the management API that I spoke about and then there's really one at least there's one main one for doing for doing enforcement, right? So on the infor well, I guess I should start the management the they're really in the management API. There's really just crud on policies. That's the first two lines and then there's crud on data, right? So remember for us we've got these two things that come into the policies in the data and so really there's just, you know, sort of standard management apis for dealing with both the management data getting them in and out and updating them within oppa. So those are the first four apis and V API is really the one that asks for for a for a policy decision, right and here the idea is

[14:51.200 - 15:51.100]
Just basically open up a get request. And so all the the service needs to do is run a get request on on basically a URL that names the policy that they want the decision from. Okay, and so it's really pretty much that simple in terms of the API. The one thing I'll mention here that that's noteworthy in this sort of rest. API space is that all of the policies and all of the data are registered at human-readable path names. So I when you create a policy even created at Food / bar / back as in the API, and then and that's reflected in the policy language as well. The same is true of data. You can register data whatever whatever path you like and then decisions are also named via path. So you could ask for a decision which is like, you know decisions / / micro-service /a pay and then you get the decisions that are for the policy that's registered at that point.

[15:51.200 - 15:53.700]
Any questions there?

[15:59.000 - 16:58.900]
The only other thing I would throw it is just that like those policy decisions when you get them you can provide arbitrary Json input when you ask those decisions. So like you can represent the API request you want to authorize or whatever is Json. You just passed that and in the body of the post request the and it turns out that I mean remember if I mentioned the term domain agnostic here, but in the intro to Oppa, but but the idea behind oppas it it should work for any kind of domain that we like and in order to make that happen sort of the what ends up working is that when you pass a when you make a when a service makes a decision a request for a decision from Oppa the input that it provides can be any arbitrary Json document and that's how open achieves this domain agnostic to City if that's a word the idea being that because you can pass in any arbitrary input that input could represent the micro service API call such as method path and user or it could represent a request to do SSH which is here's the host ID and the

[16:58.900 - 17:05.500]
Sir, or I could represent a terraform plan and we'll see examples of all these things shortly.

[17:06.600 - 18:05.200]
Does oppa support approaches for validating data? So for example, if I'm passing a jot, can you can you can you do validation on that? Yeah, so you this controls? Yeah. Typically the way that we think about it is that we do trust the input that comes in. We assume that there's some sort of trusted tunnel between the the service and Oppa but specifically with respect to jot. So mention that we have been asked a couple of times to add enough functionality inside of oppa to actually do that kind of validation in the policy itself. And then the policy language itself today already has enough control to be able to like inspect the internals of a job token to make policy decisions using the information contained within that are the open apis itself for the policy doesn't decision secured. Like how do you authenticate the service itself, which is calling into the over decision API.

[18:06.600 - 19:01.700]
So today we have Bearer tokens. If you want to do that. Typically what we you know, at least often what we do is we just we just sort of assume that there's a trusted tunnel there. But yeah Bearer tokens were voting system is running locally on the next to next to the service that policy so we assume that like low cost secure you can run it over the other server with TLS enabled if you want to like you need to encrypt the traffic like Tim said you can configure open with Bearer tokens for authentication and then obviously open would not be complete. If you couldn't write authorization policy over the open apis selves so you can do that as well. So you have you know, sort of TLS authentication and authorization on Oppa itself. And then some people have been asking about support for like Mutual TLS authentication when talking opens that's sort of on the road map.

[19:02.200 - 19:03.400]
Thank you.

[19:07.300 - 20:07.100]
Okay. So yeah, it felt like this before this kind of topic is worth spending one minute talking about the journey that we taken to get here and where we are and so, you know, we started open roughly two years ago and they 2016 and we spent basically the first year building the basic Oprah the language the the API and so and so forth last year we spend basically the whole year investigating how to use open to solve other people's real world problems, right and building a community around open and getting out and then taking what we learned by running through numerous use cases to some hill climb the language and the implementation and the API and now this year really our focus is on is on like hardening. So we're looking at building a beat to of the language with you know, some of the folks that I know were I saw on one of the docs Sarah and Tristan out of Google, so they're very interested in working with us on V2 of the language and then we're also looking at

[20:07.200 - 21:07.000]
So trying to improve the ease of use of the language make it a little bit more programmer friendly looking at performance. And then of course continuing to solve real-world problems, right and building community. So what we thought we would do for the rest of the talk is just go through some of the use cases that we we've used oppa to solve from from a number of different places. All right. All right. So here's our here's our picture of the the classes and different use cases that we've used to with that. We solved with oppa. And and so we're going to go through I think most of these I'll just highlight them, you know, so so really remember Opus designed to be the main agnostic which means you can apply it it really any level of your proverbial stack, right? So we've applied oppa sort of at the orchestration layer here with kubernetes at the individual sort of host layer to do like Docker and Linux control. We've done Integrations with oppa to sort of public cloud.

[21:07.200 - 22:07.200]
Our with with terraform to do some risk management we've done we solve these cases with oppa at the micro service API layer as well that's been pretty public around. We've been probably most public around that with Netflix in this Geo and then we've recently we started getting into or us necessarily but user just started using oppa to do some data protection stuff in this sort of cafta open SDS and Mineo space. All right, so I'm just going to go through some of these and and the ones in tried it I what I tried to do is sort of just like we can go to all 20 or however many Integrations. But but go through sort of the the key categories of Integrations that we done in these cases of be seeing the interesting thing. I did spend some time for this meeting trying to think through some of the different dimensions that we think about when we're looking at a new use case. And so we thought that this would be valuable for this for this group just because it just does sort of highlight some of the different things that you need to

[22:07.200 - 23:07.100]
Think about when you're thinking about a use case at least at least in our experience, that's the case. I'll just run through these one at a time and then very quickly, but then what I'd like to understand is from the from this group's position, like what what which of these things are most interesting to you and then I can sort of highlight those and as we talk to you in the different use cases. So the first one is just sort of basic policy like what kind of policy or even writing and and obviously this is really interesting from Anoka point of view because it's you know, oppa is fundamentally a language and so understanding what kind of policy what kinds of expressiveness requirements are needed is an important property of any use case. The second thing is data in context and this is typically, you know from open point of view data represents what's going on in the world. And so sometimes over to make policy decisions you need information that the requester does not provide for example in the micro service API case if you want to authorize an API server or sorry an API request, you may need to know whether the user that's making that

[23:07.200 - 24:05.500]
Quest is a manager in the organization. Right and that management information is not always something that comes in as part of the request. So what date and context you need to actually make decisions is valuable. The third thing here is what what do this? What do the decisions look like, you know classically with authorization policies that decision is always true false. It's loud and I may be there a couple others like not applicable but but fundamentally there, you know often allow dry and one of the things that we built into oppa from the very early days was the was the ability to make decisions that were not just allow and deny statements. You can return decisions that are numbers this for example, you want to do rate limiting or strings or sets or even dictionaries and their use cases throughout the whole show each of those. The next thing is integration, you know, in some sense you're always at the mercy of the system you're trying to integrate with when it comes to actually doing the integration. So so how does that even work and that's something that we look at for each and every use case and it's always a little bit different.

[24:06.100 - 24:55.300]
Policy management the obvious thing that we mentioned earlier, which is it every use case at least for Oppa requires a potentially a different kind of management system. And then there's performance. It turns out that use cases can vary widely in terms of performance. We've got some use cases where you know spending 10 seconds to make a policy decision is fine others where you have to come in at under, you know, a millisecond if you're going to if you're going to make a decision and then finally is terribly named here, unfortunately mode but here the idea is that they're different ways of actually enforcing policy one is the sort of obvious one, which is that you we call it proactive here, which is that you stop policy violations before they happen, right? For example, you don't deploy. You don't allow a pods be deployed on kubernetes unless

[24:56.000 - 25:37.200]
The policy says it's okay to play but there's this other version which is what we're calling reactive which is that you look at the state of the world. And you say here violations of policy. Now, I'm going to go off and fix them. Right and now this is actually more common than you would think like imagine in kubernetes. You actually change your policy and now you've got a bunch of PODS it violated that policy. Do you want to go off and fix them or do you not right? The third kind of thing here is audit. So here the idea is well, let's go off and actually just identify violations and then use them in and plug into some external system to actually let people know that they're actually violations in place other questions or comments here. Oh right and let me know which things are most important to you.

[25:44.100 - 25:45.400]
No opinions.

[25:46.800 - 26:31.200]
How like when you're in that your decommissioning state of PODS? You know, how easy it is. Is it to leave those things behind them? And that's been a pain point? No, I haven't experienced that in kubernetes. But you know in sort of other orchestration systems having decommissions, you know nodes in there that have the wrong policy. It was when one of those things where you're pulling your hair out, you're pulling your hair out and oh my God, they're like we thought there was no that those nodes were gone and they're so they're doing the wrong things.

[26:31.700 - 27:26.400]
Yeah. Well, I mean, I think one of the sort of one of our goals with oppa has always been this idea that you ought to be able to write a single policy and then apply it in any of these different modes or at least, you know to the extent that you can make that happen. And so at least with with you know, Kuba nice thing is once you sort of get this sort of pull all the data about the current state of the world, so whether it's pods or nose or whatever into into oppa as we've already articulated then the the language itself was sort of designed around a notion of a query language and so you can just ask the question. Well, like tell me which pods and nodes exist that that shouldn't write and then you can even stop watches that you know stream the results of that query back out to so appreciative that person so I guess I don't know how to answer your question except to answer it with the way opal would the way we would use oppa to help with that kind of problems. Cool.

[27:28.700 - 28:26.500]
Okay. Well, I guess is we go sorry go ahead and reasonable answer. So yeah, I just wanted this is Sarah from Google and one of the things that I think is exciting about oppa from my perspective is the ability to compose policy that might be from disparate services that need to work together. We need to reason about them together but part of the safe working group is to zoom out a bit and say well we have a whole system that might be using oppa her in one place and something else in another and how do we reason about the overall system architecture and policies writ large and so I'm curious about you know, what your thought of you know, if we're in a situation where like everybody in the world isn't going to use oppa. What are the things that we as a working group might need you to find that would help oppa live within an ecosystem. That is heterogeneous.

[28:27.400 - 29:04.000]
Yeah, I mean obviously the you know, their standards things would help here right? Like so like having a fairly simple and standard way to ask for decisions. I guess what help I mean, it would definitely help the the maybe I'll just from the users point of view like which is it as a user. I'd like to have a consistent way of managing and dealing with all these different kinds of policy systems what I'd really like those to be able to reason about how the different policies

[29:04.600 - 30:04.500]
Presumably in different languages would interact with each other and it's not clear to me what you can do there from from an outside. Like if we treat all policy languages as lock boxes and it's not clear to me what you can do there other than to have other than maybe surface actual policy decisions in some sort of format that you know some tooling to come along later and and sort of combine them. Well, I think one of the things I like survive a hypothesis that know like that the generally we're all kind of dealing with the same nouns and verbs for the most part certainly seem nouns, right? So it might be some certain amount of where we say. Okay, if you're developed if you're deploying a nap, right or sir or micro service in your in this world of deploying software that interoperate.

[30:04.500 - 31:04.400]
Other software via, you know tcp/ip, there's some set of concerns that you have and if we were to standardize like words for those concerns or apis to a query, you know or something then you could imagine people being able to compare equivalent policies, right? Obviously, if some policy system has capabilities that another policy system doesn't that's one thing that what I hear from people who have these heterogeneous infrastructure environments is there you know, they want to do something as simple as like, I want to know that you know, these these these endpoints aren't open to the world and I can't even I have to write different code for each system to even ask very simple questions and you know, and I don't know whether that's you know, what form that takes but I think that we have this

[31:04.500 - 32:04.400]
Dream of like you say like having tools that would be able to say okay. I can go across all of these systems and without writing something that is custom for every system that I work with. I know that if it conforms to the to the safe guidelines right that then might this tool will be interoperable in some way. Yeah and what I what I wondered, I mean we've talked about this in the past, which is that it would be nice. It would be wonderful if there were some ontology some schema that everyone in the world agreed on and that like represented all let's go back represented all the nouns in the you know in this landscape that we see here and I think what I've been hesitant to try to go down that road just because it seems it feels to me like a like a such a gigantic undertaking and that will never be finished. And so what I what I think I would I would wonder

[32:04.500 - 33:04.400]
About is how do we scoped what you're talking about just to something where it's like it's doable. It's an invaluable the same time and so like I think maybe the right thing to do is to do that from from a use case perspective and and you know tackle one use case at a time and once we're happy with that then then go on to the next and it's not clear to me. What else can be done there when it comes to, you know, standardizing the nouns at you know across systems as as widely disparate as the ones that are that we use every day. Yeah, man, I think there's models for that out there in the world. You know, like how do we get to really standard mime types for email? Right? Like there's processes that where we've done this on the internet before where we start with a few and there's ways to promote something to be what everybody uses and that that's that could be an exercise for the working group. It's painful consensus, but that's what we're here for.

[33:04.400 - 33:26.200]
What we're hearing is that even a few common things would be high value to the people using these systems, right? Because a lot of the auditing requires either some kind of manual inspection or custom code to and then that's always worrisome in fragile.

[33:28.100 - 34:28.000]
Yes, I'm talking about the IBM team. We're sharing how in openstack this was just left to vendors and you know, the incompatibility was incredibly cumbersome. So, you know, it's you know an opportunity. All right, it's in good shape. Maybe I should hammer on actually talk about some use cases, but we think okay. So all right, so--okay the first one we're gonna talk about here is kubb and I'll just kind of rattle on through some of this stuff and then stop me with questions. I'll try to remember to ask but if I don't just jump in Okay, so kubernetes we've done actually a number we seen actually a number of different use cases actually within kubernetes itself because there are a number of different places that are extensible enough to support a policy system. And so you know it one point we have we have an integration with the Federation control plane. So here the problem the policy

[34:28.100 - 35:27.200]
Is really given a new workload tell open decides which which communities clusters to place that workload on right? So that's the use case. There are others at the API server level around authorization and admission control here. The idea is somebody's trying to create a new pod and now open each decide either whether to allow it in or not or that we've used oppa to actually Define the mutations that need to happen to that card before it's before it slept through and then in the in the scheduler we did and we did an integration there as well to actually use policy to control effectively which the to to filter out which nodes or not or not used during scheduling Okay. So we've got more details on these the one that we get we have more details on right here in the slide deck is admission control. So here the idea is you've got this this pod effectively that we're trying to

[35:28.100 - 36:27.700]
To create there on the right-hand side. And then the way that that works is that there's a web hook that runs inside the API server and the nice thing is here that it's a generic web hook and so, you know, we didn't actually have to go in and and convince kubernetes to talk to Oppa. We could just set up Oppa as a web hook and then so then I guess the examples here that we're showing our that some of the policies that people like our will make sure that labels exist. Like every pot has a contact email address control the number of replicas based on the type of application the type of pot that were deploying make sure that there's certain metadata in place the template the other one that we've heard several times is let's use let's make sure that all the images in this pod come from a trusted repository. Like if we're if this is a production cluster, so those are just some of the use cases that we've seen there. Oh here I think maybe I'll skip through this. I don't think

[36:28.000 - 37:18.800]
People here are going to care too much about the language. I will mention though that that the me see the yeah here the that the input that comes into opal and it makes a decision is this gigantic? Yeah mouthing shown here on the left, right? It is the full pod definition. And for the people who know communities are back. This is what in some sense what differentiates oppa from our box is that when you make policy decision you get to make them given the entire pod that's trying that somebody's trying to create. All right. And then as I mentioned here the the decision in this case could just be true or false. It's it's a louder it's not but it could also be sort of a Json dictionary that defines what amounts to a Json patch for updates that must be applied to this pod before it's before it's submitted questions there.

[37:23.900 - 38:22.200]
Okay here following on this interest in use cases here a few other example policies that we've heard people use in the kubernetes admission control space. I'm not going to I'll just let you all sort of scan through those quickly. I won't bother reading them we can post the slides to this online application and throw them into the notes. People want to go to the be great. Yeah, I'll follow up and send that out to everybody. Yeah. All right. Okay. I just checked the time we've got about 20 minutes left. I will skip reading through these things. I'll just pick out a couple highlights in terms of management. We've already discussed how oppa handles management within kubernetes, right? We have the side car that pulls policies out of conflict maps and pushes kubernetes data into oppa. We actually have looked at this for both the proactive reactive as well as audit perspectives. I think we covered the rest of this here.

[38:23.800 - 39:08.700]
All right. So let's go on. All right. So another use case and this this we've seen quite a bit of interest in this is sort of micro service API authorization. So the idea here the problem that were solving is that you've got a whole collection of micro services that are doing what they do and now we need to add authorization on top of it and the idea being here that each and every API call that a micro service sees is something that it sends to Oppa to ask for an authorization decision on right and so conceptually the way that you should think about this is it oppa is running on the same host is every micro service. And so the nice thing then is that you get high performance and high availability, right? You're not painting Network hop to go hit some external service to get an authorization decision.

[39:09.400 - 39:16.700]
And now and now the idea is that you're using oppa to make those decisions on every API call.

[39:17.700 - 40:16.400]
They're different ways of integrating oppa with those microservices some some right from top to bottom. Some folks will actually just do a direct integration with oppa or what we just released. I think this week was a spring integration where even the developer doesn't even know that oppa is being used but the Java framework is actually taking every Pi calling authorizing oppa. Some folks will actually embed open as a librarian to the micro service. That's the second one the third one from the top is effectively the service mesh version where you run next to your micro service a sidecar, which is a network proxy that that handles all the network traffic and then what we do is an integration with that with that proxy so that that proxy actually asks Oprah for authorization decisions on every API call. There's another version of in the SEO world where oppa was integrated into mixer and so it can do centralized decisions there as well.

[40:17.700 - 40:40.400]
And then the last one here, I think we're just illustrating the fact that if you've got multiple micro Services running on a single host they can all use the same oppa. And so then here the interesting bit for this use case is here are the inputs that come in as I mentioned earlier. You can provide a path and a method and a source and a Target and a user and then the policy that you write makes a decision about whether or not that API calls authorized.

[40:42.500 - 40:43.400]
questions here

[40:51.200 - 41:50.900]
Looking at the sort of the the dimensions of comparison that we talked about earlier. The performance on this one is crew is critical, right? So if you're the Netflix, the number that Netflix came out with was actually twice this so two thousand requests per second is what you need and then at least for them and so like obviously the and I guess I didn't mention this previously but include manetti's the the number was more like a second right or a tenth of a second something like that. And so obviously the performance demands in this use case or are significantly different but and so consequently there there we ended up adding some functionality to Oppa to handle these really Mission critical performance critical applications. And and so that was just something that we needed to do. The other thing that we see is that for these kinds of use cases where performance is critical. It also turns out that the amount of data that they typically use is smaller and the and the policies are written.

[41:51.200 - 42:09.000]
Are typically much simpler as well. These decisions are basically allowing tonight roof also, classic authorization decisions. And we've seen people either do these Integrations with go Library running it as a as a Daemon or the other Integrations that we talked about with the service meshes.

[42:10.500 - 43:09.300]
So this question I see that you have a translation into recall there. So what's the reason for that? Well, what is the other language? Oh, yeah. Yeah, right. So this was interesting. So this has come up several times in the last couple months where people want to use oppa for this this particular use case, but what they want to do is sort of split off think of this as maybe a service graph like so they've got some yam will file the represents a service graph and what they want to do is basically treat that as the actual policy and to then what happens is that the you end up writing a little bit of radio ray goes the internal opal language if you end up writing a little bit of Ray go to actually Define the semantics that gamma beta and then when opens making the decision it will sort of combine that llamo beta which binds us say the surface craft along with the Rego that defines its semantics in order to make a decision.

[43:10.500 - 43:48.400]
Simply into Rago just meeting that the one of the one of the features that we added recently to Oppa will take the data and the ammo and the Rago and compile them down into into puree go in a simple form that we can purposely evaluate various so that the idea there but that in the to use case it seems like people want to have a sort of a secondary front end to writing policy which amounts to yeah, Moe or sort of a gooey and then what they want to do is make that very easy for users or application developers to write and then at the same time they want to use oppa to actually do the enforcement.

[43:49.000 - 44:22.000]
Yeah, we can will also maybe post a link to the to the yes. I've got it. I've added a link to the bottom of that partially don't teach you this to something out and I think that I guess who the idea here is like, you know, the developers want to provide like our back configuration basically, you know to the system but the platform engineering security team building those 2D platformer must use oklet's you'd almost those are back policies. And so that's something that it's like well supported today. We're sort of continuing to to the pardon of optimism.

[44:24.700 - 45:24.100]
When it comes to management and this case Netflix ended up rolling their own their own management layer. They you know, Netflix is good at replicating State and policy is an example of that. So they rolled their own and I know is I don't know if Manish is on the call or not. I saw his name on the on the folks in the the working group, but they rolled their own the other thing that we've seen in this is using for sto using kubernetes crd custom resource definitions to store policy as well as data. That's something that I think were that may be coming out of this part of the sto in the near future and then the other thing that we've seen in terms of management as we've seen several we've seen several requests for sort of back ends that will have oppa go out and like pull policy out of post grass or S3 or something like that and so like the management there is

[45:24.700 - 45:31.400]
Is it goes beyond what open does for sure, but it's a fairly simple kind of sidecar management system.

[45:35.500 - 46:34.800]
All right, we'll keep on moving then another use case. It was interesting here is in sort of public Cloud space and this one is really focused on terraform and using terraform to manage the public Cloud resources. So they're actually kind of to use cases that came out here. So what happened was that there really two cases, right? So one of which is you've got an application developer who or a platform engineer who wants to make a change of a cloud infrastructure so they go in to terraform they make some changes to the file and then and then they want to go ahead and apply those changes. And so what is Medallia? So what Medallion wanted to do was take the plan that careful produces and compute a risk score for that plan and then decide whether or not that user is authorized to make that change all by himself without peer review.

[46:35.500 - 47:14.500]
Stopping the risk score of the clan as well as based on how senior employee they were. All right. So if you're a senior platform engineer, then your risk score my might be like a thousand and you can make any change up to that risk score. But if you're a junior developer may be your only authorized to automatically execute risk scores under a hundred or something and here the risk score that they came up with was based on the networking ports. It's you open the number of servers that you deleted and so on so forth. So this is we did convince him to add this risks or policy to our standard Library.

[47:16.100 - 47:59.900]
The second kind of use case is sort of the back end of that which is once you've already used terraform to push and manage your public Cloud resources. How do you know that people are only using terraform to actually manage that infrastructure and here the idea was that what I did was they took the I think of awf they took the AWS the state of AWS all the resources in it. And then they took the terraform State file which represents what resources terraform nose is under its management. It taught us both of those into open. Then you write policy that that look for differences, right? It's they show me a resource in the public Cloud that is not also in the terraform state.

[48:00.400 - 48:02.700]
And so they're using that for audit.

[48:04.000 - 48:07.900]
I think about those use cases.

[48:12.300 - 48:48.500]
All right, maybe the ground that I do have an example here of the kind of input that would come in that would actually ask for a in this case a risk score for this particular terraform plan. And so there was no way I know if any of you to have seen terraform plans but there's no way I could actually put on a slide so there's a whole bunch of ellipses here, but you get the basic idea that there are that it is pretty much an arbitrary Json document that tell you all the different properties that are being changed and then you've got to write some some to the policy logic that decides how risky that changes.

[48:49.000 - 48:54.600]
Here at one here. The decision here is a number. It's a you know some from risk score.

[48:57.400 - 49:41.400]
Oh and here I broke down the the sort of to terraform use cases in terms of these dimensions of comparison that we talked about performance here was not a real issue. You know, it's some person using it for the most part. So it's not a big deal and then obviously here though. The policies were quite sophisticated in terms of the kinds of inputs. They required and kinds of and in terms of the expressiveness you needed to actually compute a risk score decision was a number we talked about that that we don't really have good visibility into how they're doing policy management in either of these cases, but but what seems sort of clear is that there aren't a thousand oppas that they're using there's you know, one or two or ten so managers probably not all that.

[49:42.900 - 49:47.600]
Okay, we did all that our grip any other questions about the terraform use case.

[49:50.900 - 49:53.300]
Okay.

[49:54.600 - 50:53.900]
Moving on then this is actually a recent category and we don't have as much data here, but the recently folks have been starting to use oppa to do data protection here. We've got a couple of examples of open SDS many always new and kafka's new so although so and in fact, there's so I don't have a ton to say here other than what I try to do is again talk through the how each of these use cases, of course correspond to those those early Dimensions that we talked about. Oh and there's another one here rate-limiting that I didn't have on the demographic. This is also new. So for the rate limiting use case the idea is that somebody wants to set up policies to control Network great limits. And so we're still not quite sure exactly what they're what they're doing there. But we do expect is that the performance is pretty high again. This is sort of close to the micro service API case and again, they're doing this thing that torrent talked about or then I guess I was into to where

[50:54.500 - 51:12.800]
Have a GUI or a camel file for for writing the sort of the core the Crux of the policy that people care about and then they're effectively treating that as data when they author policy and Rego here. Obviously the decisions a number in the policy management we know is going to be custom.

[51:13.900 - 51:19.600]
Data protection is pretty similar here. I don't think there's anything new again performance is going to be key.

[51:22.100 - 51:25.100]
Decisions are typically allowed in eyes far as we can tell in this case.

[51:26.200 - 52:26.000]
I have a basic question. I mean we're going to make a difference a lot of use cases. There are different resources outline there does oppa have like a specific schema for how resources are identified and you know, like basically defined and you know, like how attributes are set for those resources or is it like very open-ended? It's like a Json data file that gets uploaded and then you you know, like write a policy on that. Yes. It's the latter. So we do not impose a schema on anyone and you know, as I sort of mentioned earlier, I like I wouldn't know how to begin that right. And so what we did instead is what you what you mentioned second which is the input that you provide to Oklahoma is any arbitrary Json document and then the policy language, you know what that schema is going to be when you're writing policy and then you express the logic that makes whatever decision you need it to make there in the in the policy language. So they're sort of basically a contract but between the

[52:26.200 - 53:26.100]
The person who is setting up enforcement and doing that integration and the person writing policy so that once the the integration for enforcement is done then you know the schema that you're writing policy of and how does the user identity itself come into the policy decision-making like so you can write policies that in you know, like you have example policies where you have a user right for which that policy is applicable but in a real-life use case like Howard, how does the user context flow into the policy like typical example, they counted Netflix to it or in the communities example. Yeah. So the the standard way for for is to use something like a job right? So, I mean it's sort of an obvious way to do this guy. So you have users authenticate through a jot and then you pass that jaw into Oppa Oppa does have support special support for jobs that you can

[53:26.100 - 54:25.600]
When inspecting internals and yeah, and then we're we've had a couple of requests actually be able to validate tokens within the policy. So but in those cases, we haven't sort of made again. It's the same sort of questions the first which is we don't require any sort of authentication scheme. It's pretty open-ended right now. So you can pass in tokens as part of the input here, right? Just imagine there's another field in this input document that's like called token. And so and so in that sense, we sort of assume that the user has solved authentication in some way shape or form and they have a trusted and so they can provide that user and however, they however they like and then again when you're writing policy, you know how that user is being represented. So like in the case of spring for example, like they have a whole way of representing user details, so we just take that

[54:26.100 - 55:26.000]
Object which slice send it into open as Json right? It's that you get you know, whether or not like the account is locked or like whatever the attributes are that they Define I like the subject on the principle, right, but they already have a schema for that as we don't, you know force that to change. Anyway, we just let that get loaded in the open as data and then you can write policy over it. So there's no there's no coupling between oppa and these these like the way projects choose to represent their information right in the thing. I'll add to that is that you know, one of the you sort of want both of these things, right? What you really like is to have our canonical way of writing policy overused. But what you'd also like is to make integration super simple so that you can turn out a whole bunch of these things. And so the question is how do you achieve both right? Because if you couple oppa is as foreign said and then to the actual enforcement Point well, then you gotta change oppa for every enforcement point that doesn't work very well. So we've done the opposite which is say well, we're not going to require any sort of schema for users.

[55:26.100 - 56:26.000]
Resources and open will accept any sort of any sort of Json data as input. But then in the policy language the idea is that it's expressive enough to be able to codify schemas or oncology or whatever you want to call them so that you can still author policy at this sort of with this sort of canonical nouns canonical user formats or whatever and then you just write a little bit of policy that connects whatever format that data comes in as whether it's users or researchers or whatever into that canonical schema. So what we do is we sort of try to to give people The Best of Both Worlds make the Integrations, especially simple, but also give people the option of writing sort of canonical policies. And so what sort of missing there is sort of a standard library that says well for spring for a spring integration than here's how you map the spring user data into this canonical data format and for a kubernetes integration here.

[56:26.000 - 56:34.900]
How you map it to the kubernetes user information into that same canonical format. Now we support that we support that kind of logic, but it's just not in the standard Library.

[56:36.500 - 57:36.400]
Thank you. I have a question that why do you only use the data and the policies as input to the decision or can opener call out to other services as well for example to do George validation yet. If you write that by hand, you would have to be able to call and and certificates to validate. Right? So the right picture in your head is that there's the the input that comes in which is shown here. There's the data that you can load from any data source from any kind of system on the planet and then there's a policy of course and then all of that is local to the decision and then fairly recently. We added the capability to within policy go and make an HTTP call to an external system here. The idea is there the use case here is really one where you can't for whatever reason load that data into oppa. And so what you decide is that I'm going to take an external. I'm going to take a dependency on some.

[57:36.500 - 58:08.900]
Colonel service and you know the consequences of that from a performance and availability perspective. I'm willing to take that that availability and performance hit because there's just no other practical way to get the data. I need in to make a policy decision. So for example, if you had a gigantic database it was a terabyte large. Well, you're not going to load that into oppa and if what you know, is that on every policy. I only need to make a single. You know, I only need to check if a single row exist in that in that in that database. Well, then you can use that external connector to go out during policy evaluation and check if that road exists.

[58:09.300 - 59:09.100]
And then another thing have you ever looked into obligations allowing you to manipulate the data that gives you some interesting policy. Yeah. Yeah. Yeah for sure. Yeah. So yeah, we've been where as I mentioned earlier, we're working closely with Tristan and Sarah and they're all they know all about obligations and advice. Yes, exactly. So, yeah, exactly and So the plan is for for in open today, you can express those kinds of Concepts because because the policy decisions can be these arbitrary Json documents they can they can you can include well, here's the advice and here the obligations there's no and so so from the caller's point of view it can you can return those kind that kind of information. There's no sir first or support though inside of oppa to do that and that's not a like a thing that open knows about but in sunscreens, that's okay as long as you can express the obligations and advice that you care about because it's the

[59:09.200 - 59:58.600]
Is really on the client to actually do something with that advice in those obligations. But like I said, Sarah and Tristan are the experts there and we'll learn more as we go forward with them and be too. Yeah, I think that we're really excited about like that that capability right and I think taking that layered approach makes a lot of sense like not putting like we don't need to put all of the concerns and how it's going to be used into the policy evaluation itself infected stronger. If we don't right, let's only put the concepts into it that we really really need to because then it's powerful and can be used across many domains right at least. That's my current thinking will sound exactly yeah. We're on the same page for that for sure.

[59:59.600 - 01:00:47.300]
Okay, I do have some lessons learned. I'm not going to because we're out of time but I'll leave you with this stars on get Hub and and to end and participate on slack would be great. So we'll try to post these slides on slide share link in the docs questions and there's lots of people talking about fiscal policy concerns on the slack or so a lot of a lot of time that the conversation drifts outside of just like a Horseman API. Are you doing forth like a tough enforcement plane and it gets into the manager plane? And so we'd love to have on there that have experience with that could contribute to the discussion. So yeah. Thanks a lot for giving us the opportunity to thank you.

[01:00:48.700 - 01:01:11.500]
Any final questions or comments? Thank you. It was a wonderful presentation. Very informative. Thank you. All right. This is fun, which do it again. Any time. Thanks Tim thanks to him. I really appreciate you is helping us establish this use case. All right. Thanks everybody. See you next week.